{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf74f8-96a9-4f8e-9887-11c10a9362f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Injest Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a4614-9833-4f4d-bd1d-7ef49d038fd5",
   "metadata": {},
   "source": [
    "# 1. Coverage data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fad45-4f96-48cb-a206-35e72d7bcea0",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5133ad1b-7afe-4f25-8aae-05449d46c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Function to read the Excel file\n",
    "def read_excel_file(file_path):\n",
    "    # Read the Excel file using pandas\n",
    "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    return df\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4f61f6a-8627-44b3-9449-598138a78805",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_home = \"/home/wesley/github/etheleon/national_analysis/data/climate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5f2be-db0c-4fe5-99bb-d38f727f6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://postgres:<redacted>@localhost/dengue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270a3362-96f5-4ae7-b1a2-0ffefcd6f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_into_postgresql(df, connection):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Prepare the INSERT query\n",
    "    insert_query = sql.SQL(\"\"\"\n",
    "        INSERT INTO national_analysis.site_release (\n",
    "            postal, sector_id, premise_type, release_date, total_dwelling\n",
    "        ) VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\")\n",
    "\n",
    "    # Iterate over the rows in the DataFrame and insert them into the table\n",
    "    for index, row in df.iterrows():\n",
    "        cursor.execute(insert_query, (\n",
    "            int(row['postal']),\n",
    "            row['sector_id'],\n",
    "            row['premise_type'],\n",
    "            row['release_date'] if pd.notnull(row['release_date']) else None,  # Handle NA dates\n",
    "            int(row['total_dwelling']) if pd.notnull(row['total_dwelling']) else None\n",
    "        ))\n",
    "\n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully into national_analysis.site_release!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14adb4f0-f4e4-4ac0-8846-2b4221086f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_site_home = \"/home/wesley/github/etheleon/national_analysis/data/release_site\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a4dc5bc-cd8d-439f-be49-0f9a104e2abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdb.xlsx  landed.xlsx  rct.xlsx\n"
     ]
    }
   ],
   "source": [
    "! ls $release_site_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af133bdd-874e-47f5-ba90-d2da544c3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'dbname': 'dengue',\n",
    "    'user': 'postgres',\n",
    "    'password': '<redacted>',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "connection = psycopg2.connect(**db_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c435f3-4ef2-4839-bd75-eb255a27dfe1",
   "metadata": {},
   "source": [
    "## HDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4965c64a-e8ef-4c06-b9e8-c83694f22565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HDB_RESIDENTIAL'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdb_df = read_excel_file(os.path.join(release_site_home, \"hdb.xlsx\"))\n",
    "hdb_df[\"PremiseType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c28fa18-a28c-440e-84e0-34669bd510b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal</th>\n",
       "      <th>premise_type</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>total_dwelling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>520103</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL332</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>520104</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL332</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>520140</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL306</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>520143</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL306</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520202</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL119</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>391092</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>392091</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>391091</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>391090</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>392090</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2782 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      postal     premise_type sector_id release_date  total_dwelling\n",
       "0     520103  HDB_RESIDENTIAL     FL332   2020-02-17             126\n",
       "1     520104  HDB_RESIDENTIAL     FL332   2020-02-17             119\n",
       "2     520140  HDB_RESIDENTIAL     FL306   2019-11-04             114\n",
       "3     520143  HDB_RESIDENTIAL     FL306   2019-11-04              80\n",
       "4     520202  HDB_RESIDENTIAL     FL119   2020-02-17             140\n",
       "...      ...              ...       ...          ...             ...\n",
       "2777  391092  HDB_RESIDENTIAL     FL848   2024-02-28             180\n",
       "2778  392091  HDB_RESIDENTIAL     FL848   2024-02-28             182\n",
       "2779  391091  HDB_RESIDENTIAL     FL848   2024-02-28             201\n",
       "2780  391090  HDB_RESIDENTIAL     FL848   2024-02-28             204\n",
       "2781  392090  HDB_RESIDENTIAL     FL848   2024-02-28             187\n",
       "\n",
       "[2782 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdb_df_short = (\n",
    "    hdb_df[\n",
    "        [\"Postal\", \"PremiseType\", \"Sector_ID\", \n",
    "         \"FirstSustainedReleaseDate_Postal\",\n",
    "         \"TotalDwelling\"]]\n",
    "    .rename(columns={\n",
    "    'Postal': 'postal',\n",
    "    'PremiseType': 'premise_type',\n",
    "    'Sector_ID': 'sector_id',\n",
    "    'FirstSustainedReleaseDate_Postal': 'release_date',\n",
    "    'TotalDwelling': 'total_dwelling'\n",
    "    })\n",
    ")\n",
    "hdb_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc6e9fa7-9d39-455d-9bf0-b6b361f58821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into national_analysis.site_release!\n"
     ]
    }
   ],
   "source": [
    "insert_data_into_postgresql(hdb_df_short, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9fcf6185-f622-4359-aa62-a5148391a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebdc90-07b0-4006-8e18-071c7982a7b3",
   "metadata": {},
   "source": [
    "There are sites where wolbachia has never been released before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa741837-02d7-4beb-bb84-be0d57a5ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost/dengue\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>postal</th>\n",
       "            <th>sector_id</th>\n",
       "            <th>premise_type</th>\n",
       "            <th>release_date</th>\n",
       "            <th>total_dwelling</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>681801</td>\n",
       "            <td>FL767</td>\n",
       "            <td>HDB_RESIDENTIAL</td>\n",
       "            <td>None</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(681801, 'FL767', 'HDB_RESIDENTIAL', None, 96)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "select * from national_analysis.site_release where postal = 681801"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b983b9-0bd6-4504-be70-533e0f412a52",
   "metadata": {},
   "source": [
    "## Landed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4ec97fa-8fac-4b81-a2c0-e4f5064ce7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LANDED_RESIDENTIAL'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landed_df = read_excel_file(os.path.join(release_site_home, \"landed.xlsx\"))\n",
    "landed_df[\"PremiseType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dce429b-47d1-4f16-aab3-e32a7d97336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postal</th>\n",
       "      <th>Block</th>\n",
       "      <th>PremiseType</th>\n",
       "      <th>RO</th>\n",
       "      <th>Constituency</th>\n",
       "      <th>EHISectorID</th>\n",
       "      <th>Sector_ID</th>\n",
       "      <th>StudyArea</th>\n",
       "      <th>ReleaseSiteSincePhase2.2</th>\n",
       "      <th>FirstReleaseDate_Postal</th>\n",
       "      <th>...</th>\n",
       "      <th>FirstReleaseEYEW_Sector</th>\n",
       "      <th>StartRelease_FullSector</th>\n",
       "      <th>StartRelease_SectorAdjusted</th>\n",
       "      <th>TotalDwelling</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>FirstSustainedReleaseDate_Postal</th>\n",
       "      <th>FirstSustainedReleaseEmonth_Postal</th>\n",
       "      <th>FirstSustainedReleaseEyear.Eweek_Postal</th>\n",
       "      <th>Num_Gravitrap_deployed_2022EW17/18</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415800</td>\n",
       "      <td>14A</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415801</td>\n",
       "      <td>14B</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415899</td>\n",
       "      <td>396</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO226</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416507</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>416508</td>\n",
       "      <td>2</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>277080</td>\n",
       "      <td>20</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15776</th>\n",
       "      <td>277261</td>\n",
       "      <td>6</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15777</th>\n",
       "      <td>277321</td>\n",
       "      <td>61</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>276844</td>\n",
       "      <td>9</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15779</th>\n",
       "      <td>277003</td>\n",
       "      <td>11</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15780 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Postal Block         PremiseType    RO         Constituency  \\\n",
       "0      415800   14A  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "1      415801   14B  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "2      415899   396  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "3      416507     1  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "4      416508     2  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "...       ...   ...                 ...   ...                  ...   \n",
       "15775  277080    20  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "15776  277261     6  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "15777  277321    61  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "15778  276844     9  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "15779  277003    11  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "\n",
       "       EHISectorID Sector_ID            StudyArea  \\\n",
       "0              NaN     CO203  MarineParade_landed   \n",
       "1              NaN     CO203  MarineParade_landed   \n",
       "2              NaN     CO226  MarineParade_landed   \n",
       "3              NaN     CO203  MarineParade_landed   \n",
       "4              NaN     CO203  MarineParade_landed   \n",
       "...            ...       ...                  ...   \n",
       "15775          NaN      CO92       Holland_landed   \n",
       "15776          NaN      CO92       Holland_landed   \n",
       "15777          NaN      CO92       Holland_landed   \n",
       "15778          NaN      CO92       Holland_landed   \n",
       "15779          NaN      CO92       Holland_landed   \n",
       "\n",
       "               ReleaseSiteSincePhase2.2 FirstReleaseDate_Postal  ...  \\\n",
       "0      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "1      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "2      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "3      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "4      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "...                                 ...                     ...  ...   \n",
       "15775       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "15776       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "15777       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "15778       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "15779       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "\n",
       "       FirstReleaseEYEW_Sector  StartRelease_FullSector  \\\n",
       "0                      2022.17                  2022.17   \n",
       "1                      2022.17                  2022.17   \n",
       "2                      2022.17                  2022.17   \n",
       "3                      2022.17                  2022.17   \n",
       "4                      2022.17                  2022.17   \n",
       "...                        ...                      ...   \n",
       "15775                      NaN                      NaN   \n",
       "15776                      NaN                      NaN   \n",
       "15777                      NaN                      NaN   \n",
       "15778                      NaN                      NaN   \n",
       "15779                      NaN                      NaN   \n",
       "\n",
       "       StartRelease_SectorAdjusted  TotalDwelling  DATA_TYPE  \\\n",
       "0                          2022.17              1       extg   \n",
       "1                          2022.17              1       extg   \n",
       "2                          2022.17              1       extg   \n",
       "3                          2022.17              1       extg   \n",
       "4                          2022.17              1       extg   \n",
       "...                            ...            ...        ...   \n",
       "15775                          NaN              1       extg   \n",
       "15776                          NaN              1       extg   \n",
       "15777                          NaN              1       extg   \n",
       "15778                          NaN              1       extg   \n",
       "15779                          NaN              1       extg   \n",
       "\n",
       "       FirstSustainedReleaseDate_Postal FirstSustainedReleaseEmonth_Postal  \\\n",
       "0                            2022-04-30                                Apr   \n",
       "1                            2022-04-30                                Apr   \n",
       "2                            2022-04-30                                Apr   \n",
       "3                            2022-04-30                                Apr   \n",
       "4                            2022-04-30                                Apr   \n",
       "...                                 ...                                ...   \n",
       "15775                               NaT                                NaN   \n",
       "15776                               NaT                                NaN   \n",
       "15777                               NaT                                NaN   \n",
       "15778                               NaT                                NaN   \n",
       "15779                               NaT                                NaN   \n",
       "\n",
       "      FirstSustainedReleaseEyear.Eweek_Postal  \\\n",
       "0                                     2022.17   \n",
       "1                                     2022.17   \n",
       "2                                     2022.17   \n",
       "3                                     2022.17   \n",
       "4                                     2022.17   \n",
       "...                                       ...   \n",
       "15775                                     NaN   \n",
       "15776                                     NaN   \n",
       "15777                                     NaN   \n",
       "15778                                     NaN   \n",
       "15779                                     NaN   \n",
       "\n",
       "      Num_Gravitrap_deployed_2022EW17/18  Remarks  \n",
       "0                                    0.0      NaN  \n",
       "1                                    0.0      NaN  \n",
       "2                                    0.0      NaN  \n",
       "3                                    0.0      NaN  \n",
       "4                                    1.0      NaN  \n",
       "...                                  ...      ...  \n",
       "15775                                NaN      NaN  \n",
       "15776                                NaN      NaN  \n",
       "15777                                NaN      NaN  \n",
       "15778                                NaN      NaN  \n",
       "15779                                NaN      NaN  \n",
       "\n",
       "[15780 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9540767e-3087-47c6-9e8d-ee0b86817028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal</th>\n",
       "      <th>premise_type</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>total_dwelling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415800</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO203</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415801</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO203</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415899</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO226</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416507</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO203</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>416508</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO203</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>277080</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15776</th>\n",
       "      <td>277261</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15777</th>\n",
       "      <td>277321</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>276844</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15779</th>\n",
       "      <td>277003</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15780 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       postal        premise_type sector_id release_date  total_dwelling\n",
       "0      415800  LANDED_RESIDENTIAL     CO203   2022-04-30               1\n",
       "1      415801  LANDED_RESIDENTIAL     CO203   2022-04-30               1\n",
       "2      415899  LANDED_RESIDENTIAL     CO226   2022-04-30               1\n",
       "3      416507  LANDED_RESIDENTIAL     CO203   2022-04-30               1\n",
       "4      416508  LANDED_RESIDENTIAL     CO203   2022-04-30               1\n",
       "...       ...                 ...       ...          ...             ...\n",
       "15775  277080  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "15776  277261  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "15777  277321  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "15778  276844  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "15779  277003  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "\n",
       "[15780 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landed_df_short = (\n",
    "    landed_df[\n",
    "        [\"Postal\", \"PremiseType\", \"Sector_ID\", \n",
    "         \"FirstSustainedReleaseDate_Postal\",\n",
    "         \"TotalDwelling\"]]\n",
    "    .rename(columns={\n",
    "    'Postal': 'postal',\n",
    "    'PremiseType': 'premise_type',\n",
    "    'Sector_ID': 'sector_id',\n",
    "    'FirstSustainedReleaseDate_Postal': 'release_date',\n",
    "    'TotalDwelling': 'total_dwelling'\n",
    "    })\n",
    ")\n",
    "landed_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91f8bb25-9842-44d1-ace2-1b2b7abf263c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postal</th>\n",
       "      <th>Block</th>\n",
       "      <th>PremiseType</th>\n",
       "      <th>RO</th>\n",
       "      <th>Constituency</th>\n",
       "      <th>EHISectorID</th>\n",
       "      <th>Sector_ID</th>\n",
       "      <th>StudyArea</th>\n",
       "      <th>ReleaseSiteSincePhase2.2</th>\n",
       "      <th>FirstReleaseDate_Postal</th>\n",
       "      <th>...</th>\n",
       "      <th>FirstReleaseEYEW_Sector</th>\n",
       "      <th>StartRelease_FullSector</th>\n",
       "      <th>StartRelease_SectorAdjusted</th>\n",
       "      <th>TotalDwelling</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>FirstSustainedReleaseDate_Postal</th>\n",
       "      <th>FirstSustainedReleaseEmonth_Postal</th>\n",
       "      <th>FirstSustainedReleaseEyear.Eweek_Postal</th>\n",
       "      <th>Num_Gravitrap_deployed_2022EW17/18</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>418934</td>\n",
       "      <td>14</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>418934</td>\n",
       "      <td>14A</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>418934</td>\n",
       "      <td>14B</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>418934</td>\n",
       "      <td>14C</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Postal Block         PremiseType    RO         Constituency  EHISectorID  \\\n",
       "165  418934    14  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee          NaN   \n",
       "166  418934   14A  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee          NaN   \n",
       "167  418934   14B  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee          NaN   \n",
       "168  418934   14C  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee          NaN   \n",
       "\n",
       "    Sector_ID            StudyArea          ReleaseSiteSincePhase2.2  \\\n",
       "165     CO203  MarineParade_landed  MarineParade_landed_2022EW17_Apr   \n",
       "166     CO203  MarineParade_landed  MarineParade_landed_2022EW17_Apr   \n",
       "167     CO203  MarineParade_landed  MarineParade_landed_2022EW17_Apr   \n",
       "168     CO203  MarineParade_landed  MarineParade_landed_2022EW17_Apr   \n",
       "\n",
       "    FirstReleaseDate_Postal  ...  FirstReleaseEYEW_Sector  \\\n",
       "165              2022-04-30  ...                  2022.17   \n",
       "166              2022-04-30  ...                  2022.17   \n",
       "167              2022-04-30  ...                  2022.17   \n",
       "168              2022-04-30  ...                  2022.17   \n",
       "\n",
       "     StartRelease_FullSector  StartRelease_SectorAdjusted  TotalDwelling  \\\n",
       "165                  2022.17                      2022.17              1   \n",
       "166                  2022.17                      2022.17              1   \n",
       "167                  2022.17                      2022.17              1   \n",
       "168                  2022.17                      2022.17              1   \n",
       "\n",
       "     DATA_TYPE  FirstSustainedReleaseDate_Postal  \\\n",
       "165       extg                        2022-04-30   \n",
       "166       extg                        2022-04-30   \n",
       "167       extg                        2022-04-30   \n",
       "168       extg                        2022-04-30   \n",
       "\n",
       "    FirstSustainedReleaseEmonth_Postal  \\\n",
       "165                                Apr   \n",
       "166                                Apr   \n",
       "167                                Apr   \n",
       "168                                Apr   \n",
       "\n",
       "    FirstSustainedReleaseEyear.Eweek_Postal  \\\n",
       "165                                 2022.17   \n",
       "166                                 2022.17   \n",
       "167                                 2022.17   \n",
       "168                                 2022.17   \n",
       "\n",
       "    Num_Gravitrap_deployed_2022EW17/18  Remarks  \n",
       "165                                0.0      NaN  \n",
       "166                                0.0      NaN  \n",
       "167                                0.0      NaN  \n",
       "168                                0.0      NaN  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landed_df.query(\"Postal == 418934\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f3ab64f-ebf3-444c-8b32-7a6c47c51f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "landed_df_short_agg = landed_df_short.groupby(\n",
    "    ['postal', 'premise_type', 'sector_id', 'release_date'])['total_dwelling'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e625d56-1569-4e9f-bae9-a5e270b1c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into national_analysis.site_release!\n"
     ]
    }
   ],
   "source": [
    "insert_data_into_postgresql(landed_df_short_agg, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24a1bd09-34d1-41a9-96c2-b4d943d12e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost/dengue\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>postal</th>\n",
       "            <th>sector_id</th>\n",
       "            <th>premise_type</th>\n",
       "            <th>release_date</th>\n",
       "            <th>total_dwelling</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>418934</td>\n",
       "            <td>CO203</td>\n",
       "            <td>LANDED_RESIDENTIAL</td>\n",
       "            <td>2022-04-30</td>\n",
       "            <td>4</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(418934, 'CO203', 'LANDED_RESIDENTIAL', datetime.date(2022, 4, 30), 4)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "select * from national_analysis.site_release where postal = 418934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc93998c-d507-4a2a-af89-3afab996b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5b9e954-bb13-4754-94d7-33da12bb7dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HDB_RESIDENTIAL'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rct_df = read_excel_file(os.path.join(release_site_home, \"rct.xlsx\"))\n",
    "rct_df[\"PremiseType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e97d354c-ebc8-4a4c-a853-26ed9073b554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal</th>\n",
       "      <th>premise_type</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>total_dwelling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360081</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360082</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360083</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370019</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370020</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>670608</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>670609</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>670610</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>670611</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>670612</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2259 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      postal     premise_type sector_id release_date  total_dwelling\n",
       "0     360081  HDB_RESIDENTIAL      FL20   2022-07-29             130\n",
       "1     360082  HDB_RESIDENTIAL      FL20   2022-07-29              94\n",
       "2     360083  HDB_RESIDENTIAL      FL20   2022-07-29              93\n",
       "3     370019  HDB_RESIDENTIAL      FL20   2022-07-29             120\n",
       "4     370020  HDB_RESIDENTIAL      FL20   2022-07-29             120\n",
       "...      ...              ...       ...          ...             ...\n",
       "2254  670608  HDB_RESIDENTIAL     FL727          NaT              80\n",
       "2255  670609  HDB_RESIDENTIAL     FL727          NaT             172\n",
       "2256  670610  HDB_RESIDENTIAL     FL727          NaT              80\n",
       "2257  670611  HDB_RESIDENTIAL     FL727          NaT             170\n",
       "2258  670612  HDB_RESIDENTIAL     FL727          NaT             123\n",
       "\n",
       "[2259 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rct_df_short = (\n",
    "    rct_df[\n",
    "        [\"Postal\", \"PremiseType\", \"Sector_ID\", \n",
    "         \"FirstSustainedReleaseDate_Postal\",\n",
    "         \"TotalDwelling\"]]\n",
    "    .rename(columns={\n",
    "    'Postal': 'postal',\n",
    "    'PremiseType': 'premise_type',\n",
    "    'Sector_ID': 'sector_id',\n",
    "    'FirstSustainedReleaseDate_Postal': 'release_date',\n",
    "    'TotalDwelling': 'total_dwelling'\n",
    "    })\n",
    ")\n",
    "rct_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4606a4ea-6b3a-46e7-aa90-716746d3a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into national_analysis.site_release!\n"
     ]
    }
   ],
   "source": [
    "insert_data_into_postgresql(rct_df_short, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3d2542f-e98f-4f3d-8837-98fa0a8effef",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47745a67-2470-4af3-a363-bc8f7d41e34d",
   "metadata": {},
   "source": [
    "# 2. Climate data\n",
    "\n",
    "In the paper, only two climate features were used \n",
    "* `max_t_scale_12_wk_avg_0`\n",
    "* `days_no_rain_12_wk_total_0`\n",
    "\n",
    "\n",
    "There exists two types of files `DBT_RH` which stands for Dry Bulb Temperature (DBT) + Relative Humidity (RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e322e43-a62b-4b74-b053-8a705b338fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " forecast\n",
      "'Weekly DBT_RH 20221226-20230101.csv'\n",
      "'Weekly DBT_RH 20230102-20230108.csv'\n",
      "'Weekly DBT_RH 20230109-20230115.csv'\n",
      "'Weekly DBT_RH 20230116-20230122.csv'\n",
      "'Weekly DBT_RH 20230123-20230129.csv'\n",
      "'Weekly DBT_RH 20230130-20230205.csv'\n",
      "'Weekly DBT_RH 20230206-20230212.csv'\n",
      "'Weekly DBT_RH 20230213-20230219.csv'\n",
      "'Weekly DBT_RH 20230220-20230226.csv'\n",
      "'Weekly DBT_RH 20230227-20230305.csv'\n",
      "'Weekly DBT_RH 20230306-20230312.csv'\n",
      "'Weekly DBT_RH 20230313-20230319.csv'\n",
      "'Weekly DBT_RH 20230320-20230326.csv'\n",
      "'Weekly DBT_RH 20230327-20230402.csv'\n",
      "'Weekly DBT_RH 20230403-20230409.csv'\n",
      "'Weekly DBT_RH 20230410-20230416.csv'\n",
      "'Weekly DBT_RH 20230417-20230423.csv'\n",
      "'Weekly DBT_RH 20230424-20230430.csv'\n",
      "'Weekly DBT_RH 20230501-20230507.csv'\n",
      "'Weekly DBT_RH 20230508-20230514.csv'\n",
      "'Weekly DBT_RH 20230515-20230521.csv'\n",
      "'Weekly DBT_RH 20230522-20230528.csv'\n",
      "'Weekly DBT_RH 20230529-20230604_amended.csv'\n",
      "'Weekly DBT_RH 20230605-20230611.csv'\n",
      "'Weekly DBT_RH 20230612-20230618.csv'\n",
      "'Weekly DBT_RH 20230619-20230625.csv'\n",
      "'Weekly DBT_RH 20230626-20230702.csv'\n",
      "'Weekly DBT_RH 20230703-20230709.csv'\n",
      "'Weekly DBT_RH 20230710-20230716.csv'\n",
      "'Weekly DBT_RH 20230717-20230723.csv'\n",
      "'Weekly DBT_RH 20230724-20230730.csv'\n",
      "'Weekly DBT_RH 20230731-20230806.csv'\n",
      "'Weekly DBT_RH 20230807-20230813.csv'\n",
      "'Weekly DBT_RH 20230814-20230820.csv'\n",
      "'Weekly DBT_RH 20230821-20230827.csv'\n",
      "'Weekly DBT_RH 20230828-20230903.csv'\n",
      "'Weekly DBT_RH 20230904-20230910.csv'\n",
      "'Weekly DBT_RH 20230911-20230917.csv'\n",
      "'Weekly DBT_RH 20230918-20230924.csv'\n",
      "'Weekly DBT_RH 20230925-20231001.csv'\n",
      "'Weekly DBT_RH 20231002-20231008.csv'\n",
      "'Weekly DBT_RH 20231009-20231015.csv'\n",
      "'Weekly DBT_RH 20231016-20231022.csv'\n",
      "'Weekly DBT_RH 20231023-20231029.csv'\n",
      "'Weekly DBT_RH 20231030-20231105.csv'\n",
      "'Weekly DBT_RH 20231106-20231112.csv'\n",
      "'Weekly DBT_RH 20231113-20231119.csv'\n",
      "'Weekly DBT_RH 20231120-20231126.csv'\n",
      "'Weekly DBT_RH 20231127-20231203.csv'\n",
      "'Weekly DBT_RH 20231204-20231210.csv'\n",
      "'Weekly DBT_RH 20231211-20231217.csv'\n",
      "'Weekly DBT_RH 20231218-20231224.csv'\n",
      "'Weekly DBT_RH 20231225-20231231.csv'\n",
      "'Weekly Rain 20221226-20230101.csv'\n",
      "'Weekly Rain 20230102-20230108.csv'\n",
      "'Weekly Rain 20230109-20230115.csv'\n",
      "'Weekly Rain 20230116-20230122.csv'\n",
      "'Weekly Rain 20230123-20230129.csv'\n",
      "'Weekly Rain 20230130-20230205.csv'\n",
      "'Weekly Rain 20230206-20230212.csv'\n",
      "'Weekly Rain 20230213-20230219.csv'\n",
      "'Weekly Rain 20230220-20230226.csv'\n",
      "'Weekly Rain 20230227-20230305.csv'\n",
      "'Weekly Rain 20230306-20230312.csv'\n",
      "'Weekly Rain 20230313-20230319.csv'\n",
      "'Weekly Rain 20230320-20230326.csv'\n",
      "'Weekly Rain 20230327-20230402.csv'\n",
      "'Weekly Rain 20230403-20230409.csv'\n",
      "'Weekly Rain 20230410-20230416.csv'\n",
      "'Weekly Rain 20230417-20230423.csv'\n",
      "'Weekly Rain 20230424-20230430.csv'\n",
      "'Weekly Rain 20230501-20230507.csv'\n",
      "'Weekly Rain 20230508-20230514.csv'\n",
      "'Weekly Rain 20230515-20230521.csv'\n",
      "'Weekly Rain 20230522-20230528.csv'\n",
      "'Weekly Rain 20230529-20230604.csv'\n",
      "'Weekly Rain 20230605-20230611.csv'\n",
      "'Weekly Rain 20230612-20230618.csv'\n",
      "'Weekly Rain 20230619-20230625.csv'\n",
      "'Weekly Rain 20230626-20230702.csv'\n",
      "'Weekly Rain 20230703-20230709.csv'\n",
      "'Weekly Rain 20230710-20230716.csv'\n",
      "'Weekly Rain 20230717-20230723.csv'\n",
      "'Weekly Rain 20230724-20230730.csv'\n",
      "'Weekly Rain 20230731-20230806.csv'\n",
      "'Weekly Rain 20230807-20230813.csv'\n",
      "'Weekly Rain 20230814-20230820.csv'\n",
      "'Weekly Rain 20230821-20230827.csv'\n",
      "'Weekly Rain 20230828-20230903.csv'\n",
      "'Weekly Rain 20230904-20230910.csv'\n",
      "'Weekly Rain 20230911-20230917.csv'\n",
      "'Weekly Rain 20230918-20230924.csv'\n",
      "'Weekly Rain 20230925-20231001.csv'\n",
      "'Weekly Rain 20231002-20231008.csv'\n",
      "'Weekly Rain 20231009-20231015.csv'\n",
      "'Weekly Rain 20231016-20231022.csv'\n",
      "'Weekly Rain 20231023-20231029.csv'\n",
      "'Weekly Rain 20231030-20231105.csv'\n",
      "'Weekly Rain 20231106-20231112.csv'\n",
      "'Weekly Rain 20231113-20231119.csv'\n",
      "'Weekly Rain 20231120-20231126.csv'\n",
      "'Weekly Rain 20231127-20231203.csv'\n",
      "'Weekly Rain 20231204-20231210.csv'\n",
      "'Weekly Rain 20231211-20231217.csv'\n",
      "'Weekly Rain 20231218-20231224.csv'\n",
      "'Weekly Rain 20231225-20231231.csv'\n"
     ]
    }
   ],
   "source": [
    "! ls /home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a555da08-ca93-4992-8d02-3b5f0a6ba7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def read_yearly(root_dir: str):\n",
    "    csv_files = glob(os.path.join(root_dir, 'Weekly DBT_RH*.csv'))\n",
    "    print(csv_files)\n",
    "    return pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a27dda-5db8-46f7-b993-879ee6a7b8c6",
   "metadata": {},
   "source": [
    "`dbt` - Dry bulb temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a2b74ea-252b-42e7-a6a3-e19eff11048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date_str):\n",
    "    \"\"\"Try to parse a date string in either day/month/year or month/day/year format.\"\"\"\n",
    "    for fmt in ('%d/%m/%Y', '%m/%d/%Y'):\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    raise ValueError(f\"Date format not recognized for: {date_str}\")\n",
    "\n",
    "def read_dbt_rh(root_dir: str):\n",
    "    # Define the columns you want to standardize and map\n",
    "    column_mapping = {\n",
    "        'stationcode': 'station_id',\n",
    "        'id_station': 'station_id',\n",
    "        'date': 'date',\n",
    "        'dateasia/singapore(+0800)': 'date',\n",
    "        'maxdbt': 'dbt_max',\n",
    "        'mindbt': 'dbt_min',\n",
    "        'meandbt': 'dbt_mean',\n",
    "        'maxrh': 'rh_max',\n",
    "        'minrh': 'rh_min',\n",
    "        'meanrh': 'rh_mean'\n",
    "    }\n",
    "\n",
    "    # Define standard columns after renaming\n",
    "    standard_columns = [\n",
    "        'date', 'station_id', 'dbt_max', 'dbt_min', 'dbt_mean', 'rh_max', 'rh_min', 'rh_mean'\n",
    "    ]\n",
    "    \n",
    "    # Find all CSV files matching the pattern\n",
    "    csv_files = glob(os.path.join(root_dir, 'Weekly DBT_RH*.csv'))\n",
    "    # for file in csv_files:\n",
    "    #     print(file)\n",
    "    \n",
    "    # Create an empty list to store DataFrames\n",
    "    df_list = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        # Read each CSV file\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Normalize column names\n",
    "        df.columns = [col.strip().lower().replace(\" \", \"\").replace('\"', '') for col in df.columns]\n",
    "        \n",
    "        # Rename columns based on the new mapping\n",
    "        df.rename(columns=column_mapping, inplace=True)\n",
    "        \n",
    "        # Filter out the columns that match the standard columns\n",
    "        df_filtered = df[[col for col in standard_columns if col in df.columns]]\n",
    "        \n",
    "        # Encode timezone in the 'date' column\n",
    "        if 'date' in df_filtered.columns:\n",
    "            df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
    "\n",
    "        # Append the filtered DataFrame to the list\n",
    "        df_list.append(df_filtered)\n",
    "    \n",
    "    # Concatenate all DataFrames into one\n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccbd4907-42b7-45ee-9d45-4576ee197317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/441870856.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>dbt_max</th>\n",
       "      <th>dbt_min</th>\n",
       "      <th>dbt_mean</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_min</th>\n",
       "      <th>rh_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-24 00:00:00+08:00</td>\n",
       "      <td>S102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-24 00:00:00+08:00</td>\n",
       "      <td>S109</td>\n",
       "      <td>34.4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>90.9</td>\n",
       "      <td>47.2</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-24 00:00:00+08:00</td>\n",
       "      <td>S60</td>\n",
       "      <td>33.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>88.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-24 00:00:00+08:00</td>\n",
       "      <td>S116</td>\n",
       "      <td>32.2</td>\n",
       "      <td>27.5</td>\n",
       "      <td>29.3</td>\n",
       "      <td>89.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-24 00:00:00+08:00</td>\n",
       "      <td>S44</td>\n",
       "      <td>33.1</td>\n",
       "      <td>23.2</td>\n",
       "      <td>27.8</td>\n",
       "      <td>97.4</td>\n",
       "      <td>55.4</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6652</th>\n",
       "      <td>2023-08-27 00:00:00+08:00</td>\n",
       "      <td>S115</td>\n",
       "      <td>31.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>28.6</td>\n",
       "      <td>86.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>77.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6653</th>\n",
       "      <td>2023-08-27 00:00:00+08:00</td>\n",
       "      <td>S23</td>\n",
       "      <td>33.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>61.8</td>\n",
       "      <td>84.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6654</th>\n",
       "      <td>2023-08-27 00:00:00+08:00</td>\n",
       "      <td>S104</td>\n",
       "      <td>33.2</td>\n",
       "      <td>24.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>89.9</td>\n",
       "      <td>56.3</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>2023-08-27 00:00:00+08:00</td>\n",
       "      <td>S24</td>\n",
       "      <td>32.2</td>\n",
       "      <td>25.3</td>\n",
       "      <td>28.5</td>\n",
       "      <td>92.9</td>\n",
       "      <td>58.4</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6656</th>\n",
       "      <td>2023-08-27 00:00:00+08:00</td>\n",
       "      <td>S106</td>\n",
       "      <td>33.4</td>\n",
       "      <td>24.2</td>\n",
       "      <td>28.1</td>\n",
       "      <td>94.1</td>\n",
       "      <td>57.2</td>\n",
       "      <td>79.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6657 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date station_id  dbt_max  dbt_min  dbt_mean  rh_max  \\\n",
       "0    2023-04-24 00:00:00+08:00       S102      NaN      NaN       NaN     NaN   \n",
       "1    2023-04-24 00:00:00+08:00       S109     34.4     26.7      29.7    90.9   \n",
       "2    2023-04-24 00:00:00+08:00        S60     33.9     25.9      29.5    88.2   \n",
       "3    2023-04-24 00:00:00+08:00       S116     32.2     27.5      29.3    89.5   \n",
       "4    2023-04-24 00:00:00+08:00        S44     33.1     23.2      27.8    97.4   \n",
       "...                        ...        ...      ...      ...       ...     ...   \n",
       "6652 2023-08-27 00:00:00+08:00       S115     31.8     25.8      28.6    86.7   \n",
       "6653 2023-08-27 00:00:00+08:00        S23     33.1     24.0      28.1   100.0   \n",
       "6654 2023-08-27 00:00:00+08:00       S104     33.2     24.8      28.4    89.9   \n",
       "6655 2023-08-27 00:00:00+08:00        S24     32.2     25.3      28.5    92.9   \n",
       "6656 2023-08-27 00:00:00+08:00       S106     33.4     24.2      28.1    94.1   \n",
       "\n",
       "      rh_min  rh_mean  \n",
       "0        NaN      NaN  \n",
       "1       47.2     71.3  \n",
       "2       48.0     72.8  \n",
       "3       55.7     78.4  \n",
       "4       55.4     83.0  \n",
       "...      ...      ...  \n",
       "6652    62.3     77.1  \n",
       "6653    61.8     84.7  \n",
       "6654    56.3     74.0  \n",
       "6655    58.4     77.5  \n",
       "6656    57.2     79.8  \n",
       "\n",
       "[6657 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_dbt_rh(os.path.join(climate_data_home, 'weather_2023'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426751b7-4e91-4de0-927d-8e930d9c6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rainfall_data(root_dir: str):\n",
    "    # Define the columns you want to standardize and map for rainfall data\n",
    "    column_mapping = {\n",
    "        'stationcode': 'station_id',\n",
    "        'id_station': 'station_id',\n",
    "        'date': 'date',\n",
    "        'date.singapore...0800.': 'date',\n",
    "        'dateasia/singapore(+0800)': 'date',\n",
    "        'datesingapore(+0800)': 'date',\n",
    "        'dailyrainamount(mm)': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'totalrain': 'rain_amount',\n",
    "        'rainamount': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'rainamount': 'rain_amount',\n",
    "        'dailyrainamount(mm)': 'rain_amount',\n",
    "        'dailyrainamount': 'rain_amount',\n",
    "        'dailyrainamount(mm)': 'rain_amount',\n",
    "        'dailyrainamount': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'rainamount': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'dailyrainamount(mm)': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'totalrain': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "    }\n",
    "\n",
    "    standard_columns = [\n",
    "        'date', 'station_id', 'rain_amount', 'rain_duration'\n",
    "    ]\n",
    "\n",
    "    # Find all CSV files in the directory\n",
    "    # Find all CSV files matching the pattern\n",
    "    csv_files = glob(os.path.join(root_dir, 'Weekly Rain*.csv'))\n",
    "    \n",
    "    for file in csv_files:\n",
    "        if re.search(r\"20221226\", file):\n",
    "            print(file)\n",
    "    \n",
    "    # Create an empty list to store DataFrames\n",
    "    df_list = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        print(file)\n",
    "        # Read each CSV file\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Normalize column names\n",
    "        df.columns = [col.strip().lower().replace(\" \", \"\").replace('\"', '') for col in df.columns]\n",
    "        \n",
    "        # Rename columns based on the new mapping\n",
    "        df.rename(columns=column_mapping, inplace=True)\n",
    "        \n",
    "        # Filter out the columns that match the standard columns\n",
    "        df_filtered = df[[col for col in standard_columns if col in df.columns]]\n",
    "\n",
    "        # # Encode timezone in the 'date' column\n",
    "        if 'date' in df_filtered.columns:\n",
    "            df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
    "\n",
    "        # Append the filtered DataFrame to the list\n",
    "        df_list.append(df_filtered)\n",
    "        # Concatenate all DataFrames into one\n",
    "    return pd.concat(df_list, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e29fa25-b5f7-419f-be78-ffa63e1bd9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20221226-20230101.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230417-20230423.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230731-20230806.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231016-20231022.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230424-20230430.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230529-20230604.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230220-20230226.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230814-20230820.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230327-20230402.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231002-20231008.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230515-20230521.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230717-20230723.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230605-20230611.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230109-20230115.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230102-20230108.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230410-20230416.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230508-20230514.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231225-20231231.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230626-20230702.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231113-20231119.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20221226-20230101.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230206-20230212.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230904-20230910.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230619-20230625.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230306-20230312.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230130-20230205.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230918-20230924.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231009-20231015.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230213-20230219.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231211-20231217.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230320-20230326.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231120-20231126.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231030-20231105.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230227-20230305.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230522-20230528.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230911-20230917.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231106-20231112.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230828-20230903.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230925-20231001.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230710-20230716.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230403-20230409.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231023-20231029.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231218-20231224.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230313-20230319.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230821-20230827.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230501-20230507.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230116-20230122.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231204-20231210.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230807-20230813.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231127-20231203.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230612-20230618.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230703-20230709.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230123-20230129.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230724-20230730.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133540/1949860617.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>rain_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-17 00:00:00+08:00</td>\n",
       "      <td>S102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-17 00:00:00+08:00</td>\n",
       "      <td>S94</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-17 00:00:00+08:00</td>\n",
       "      <td>S215</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-17 00:00:00+08:00</td>\n",
       "      <td>S130</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-17 00:00:00+08:00</td>\n",
       "      <td>S71</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31796</th>\n",
       "      <td>2023-07-30 00:00:00+08:00</td>\n",
       "      <td>S303</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31797</th>\n",
       "      <td>2023-07-30 00:00:00+08:00</td>\n",
       "      <td>S61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31798</th>\n",
       "      <td>2023-07-30 00:00:00+08:00</td>\n",
       "      <td>S113</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31799</th>\n",
       "      <td>2023-07-30 00:00:00+08:00</td>\n",
       "      <td>S106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31800</th>\n",
       "      <td>2023-07-30 00:00:00+08:00</td>\n",
       "      <td>S108</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31801 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date station_id  rain_amount\n",
       "0     2023-04-17 00:00:00+08:00       S102          NaN\n",
       "1     2023-04-17 00:00:00+08:00        S94          2.0\n",
       "2     2023-04-17 00:00:00+08:00       S215          1.6\n",
       "3     2023-04-17 00:00:00+08:00       S130          5.6\n",
       "4     2023-04-17 00:00:00+08:00        S71          1.6\n",
       "...                         ...        ...          ...\n",
       "31796 2023-07-30 00:00:00+08:00       S303          0.0\n",
       "31797 2023-07-30 00:00:00+08:00        S61          NaN\n",
       "31798 2023-07-30 00:00:00+08:00       S113          0.4\n",
       "31799 2023-07-30 00:00:00+08:00       S106          0.0\n",
       "31800 2023-07-30 00:00:00+08:00       S108          1.4\n",
       "\n",
       "[31801 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_rainfall_data(os.path.join(climate_data_home, \"weather_2023\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5926e4-611b-4368-946c-585700c9b91e",
   "metadata": {},
   "source": [
    "## 2022-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2e4fa-047c-4063-abf7-eaeb0ee66311",
   "metadata": {},
   "source": [
    "### Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec30ec-27cb-42bb-a707-8dc85e366520",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531d947-219e-46d8-badd-719e300490bf",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c8213-fa7c-4948-8498-6c3a7b9e59dc",
   "metadata": {},
   "source": [
    "1982 - 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96b1d410-d5e2-49da-8e31-0f3bbdfb3107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>dbt_max</th>\n",
       "      <th>dbt_min</th>\n",
       "      <th>dbt_mean</th>\n",
       "      <th>rh_mean</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>28.8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>74.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>30.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>72.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>29.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>77.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>29.6</td>\n",
       "      <td>24.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>77.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137413</th>\n",
       "      <td>27/12/2021</td>\n",
       "      <td>S80</td>\n",
       "      <td>32.9</td>\n",
       "      <td>25.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>79.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137414</th>\n",
       "      <td>28/12/2021</td>\n",
       "      <td>S80</td>\n",
       "      <td>32.5</td>\n",
       "      <td>25.3</td>\n",
       "      <td>28.2</td>\n",
       "      <td>78.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137415</th>\n",
       "      <td>29/12/2021</td>\n",
       "      <td>S80</td>\n",
       "      <td>31.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>27.4</td>\n",
       "      <td>86.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137416</th>\n",
       "      <td>30/12/2021</td>\n",
       "      <td>S80</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>27.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137417</th>\n",
       "      <td>31/12/2021</td>\n",
       "      <td>S80</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>98.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date station_id  dbt_max  dbt_min  dbt_mean  rh_mean  rh_max  \\\n",
       "0         1/2/2009       S102     28.8     26.0      27.1     74.6     NaN   \n",
       "1         2/2/2009       S102     30.4     25.0      27.1     72.6     NaN   \n",
       "2         3/2/2009       S102     29.5     25.0      26.6     77.3     NaN   \n",
       "3         4/2/2009       S102     29.6     24.9      26.5     79.6     NaN   \n",
       "4         5/2/2009       S102     30.0     25.2      27.0     77.9     NaN   \n",
       "...            ...        ...      ...      ...       ...      ...     ...   \n",
       "137413  27/12/2021        S80     32.9     25.2      28.2     79.2     NaN   \n",
       "137414  28/12/2021        S80     32.5     25.3      28.2     78.2     NaN   \n",
       "137415  29/12/2021        S80     31.4     24.9      27.4     86.6     NaN   \n",
       "137416  30/12/2021        S80     31.0     24.2      27.5     87.5     NaN   \n",
       "137417  31/12/2021        S80     27.0     24.0      25.2     98.3     NaN   \n",
       "\n",
       "        rh_min  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "137413     NaN  \n",
       "137414     NaN  \n",
       "137415     NaN  \n",
       "137416     NaN  \n",
       "137417     NaN  \n",
       "\n",
       "[137418 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_2009_2021_df = pd.read_csv(os.path.join(climate_data_home, \"weather_1982_2021\", \"Daily DBT 2009-2021.csv\"))\n",
    "temperature_2009_2021_df.columns = [col.strip().lower().replace(\" \", \"\").replace('\"', '') for col in temperature_2009_2021_df.columns]\n",
    "temperature_2009_2021_df.rename(columns=  {\n",
    "        \n",
    "        'id_station': 'station_id',\n",
    "        \n",
    "        'dateasia/singapore(+0800)': 'date',\n",
    "        'maxdbt': 'dbt_max',\n",
    "        'mindbt': 'dbt_min',\n",
    "        'meandbt': 'dbt_mean',\n",
    "        'meanrh': 'rh_mean'\n",
    "    }, inplace=True)\n",
    "\n",
    "expected_columns = ['rh_max', 'rh_min', 'rh_mean']\n",
    "\n",
    "# Check if each column exists in the DataFrame, and if not, add it with NaN values\n",
    "for col in expected_columns:\n",
    "    if col not in temperature_2009_2021_df.columns:\n",
    "        temperature_2009_2021_df[col] = np.nan\n",
    "\n",
    "\n",
    "temperature_2009_2021_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37971a7-5c67-48e4-a916-c861f315541f",
   "metadata": {},
   "source": [
    "2022 is slightly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15b5362e-2d1b-4b9a-8243-0852498bbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names with max, min, and mean as suffixes\n",
    "snake_case_names = [\n",
    "    \"station\", \"year\", \"month\", \"day\", \"dbt_mean\",\n",
    "    \"rh_mean\", \"dbt_max\", \"dbt_min\",\n",
    "    \"wind_direction_scalar_mean\", \"wind_speed_scalar_kts_mean\",\n",
    "    \"wind_direction_max\", \"wind_speed_kts_max\"\n",
    "]\n",
    "\n",
    "# Read the CSV file, skipping the first row and using the custom column names\n",
    "temperature_2022_df = pd.read_csv(\"/home/wesley/github/etheleon/national_analysis/data/climate/weather_2022/Temp 2022.csv\", skiprows=1, names=snake_case_names, encoding='ISO-8859-1').loc[:, :\"dbt_min\"]\n",
    "\n",
    "expected_columns = ['rh_max', 'rh_min', 'rh_mean']\n",
    "\n",
    "# Check if each column exists in the DataFrame, and if not, add it with NaN values\n",
    "for col in expected_columns:\n",
    "    if col not in temperature_2022_df.columns:\n",
    "        temperature_2022_df[col] = np.nan\n",
    "\n",
    "temperature_2022_df.rename(columns={'station': 'station_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Combine year, month, and day into a single date column\n",
    "temperature_2022_df['date'] = pd.to_datetime(temperature_2022_df[['year', 'month', 'day']])\n",
    "temperature_2022_df.drop(columns=['year', 'month', 'day'], inplace=True)\n",
    "temperature_2022_df['date'] = temperature_2022_df['date'].dt.tz_localize('Asia/Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4dc7480-9859-4ade-a832-d8012ed65477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>dbt_mean</th>\n",
       "      <th>rh_mean</th>\n",
       "      <th>dbt_max</th>\n",
       "      <th>dbt_min</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_min</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S06</td>\n",
       "      <td>25.8</td>\n",
       "      <td>87.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-01 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S06</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-02 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S06</td>\n",
       "      <td>26.1</td>\n",
       "      <td>84.8</td>\n",
       "      <td>31.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-03 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S06</td>\n",
       "      <td>26.2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S06</td>\n",
       "      <td>28.1</td>\n",
       "      <td>75.3</td>\n",
       "      <td>34.3</td>\n",
       "      <td>25.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-05 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>S80</td>\n",
       "      <td>28.9</td>\n",
       "      <td>78.1</td>\n",
       "      <td>34.4</td>\n",
       "      <td>24.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-27 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>S80</td>\n",
       "      <td>28.4</td>\n",
       "      <td>78.8</td>\n",
       "      <td>32.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-28 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>S80</td>\n",
       "      <td>29.2</td>\n",
       "      <td>73.7</td>\n",
       "      <td>34.1</td>\n",
       "      <td>25.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-29 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>S80</td>\n",
       "      <td>29.7</td>\n",
       "      <td>75.4</td>\n",
       "      <td>34.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-30 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>S80</td>\n",
       "      <td>29.1</td>\n",
       "      <td>81.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-31 00:00:00+08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2869 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     station_id  dbt_mean  rh_mean  dbt_max  dbt_min  rh_max  rh_min  \\\n",
       "0           S06      25.8     87.5     31.0     23.4     NaN     NaN   \n",
       "1           S06      24.0     96.4     24.9     23.2     NaN     NaN   \n",
       "2           S06      26.1     84.8     31.6     23.4     NaN     NaN   \n",
       "3           S06      26.2     87.0     32.4     24.1     NaN     NaN   \n",
       "4           S06      28.1     75.3     34.3     25.2     NaN     NaN   \n",
       "...         ...       ...      ...      ...      ...     ...     ...   \n",
       "2864        S80      28.9     78.1     34.4     24.7     NaN     NaN   \n",
       "2865        S80      28.4     78.8     32.6     25.3     NaN     NaN   \n",
       "2866        S80      29.2     73.7     34.1     25.4     NaN     NaN   \n",
       "2867        S80      29.7     75.4     34.4     25.1     NaN     NaN   \n",
       "2868        S80      29.1     81.1     34.0     26.0     NaN     NaN   \n",
       "\n",
       "                          date  \n",
       "0    2022-01-01 00:00:00+08:00  \n",
       "1    2022-01-02 00:00:00+08:00  \n",
       "2    2022-01-03 00:00:00+08:00  \n",
       "3    2022-01-04 00:00:00+08:00  \n",
       "4    2022-01-05 00:00:00+08:00  \n",
       "...                        ...  \n",
       "2864 2022-05-27 00:00:00+08:00  \n",
       "2865 2022-05-28 00:00:00+08:00  \n",
       "2866 2022-05-29 00:00:00+08:00  \n",
       "2867 2022-05-30 00:00:00+08:00  \n",
       "2868 2022-05-31 00:00:00+08:00  \n",
       "\n",
       "[2869 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_2022_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf8e7a3c-9c60-43b5-b331-34b34ae5be04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/441870856.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/441870856.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date).dt.tz_localize('Asia/Singapore')\n"
     ]
    }
   ],
   "source": [
    "temperature_df = pd.concat([\n",
    "    temperature_2009_2021_df,\n",
    "    temperature_2022_df,\n",
    "    read_dbt_rh(os.path.join(climate_data_home, 'weather_2023')),\n",
    "    read_dbt_rh(os.path.join(climate_data_home, 'weather_2024')),\n",
    "],     ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e71099d6-583a-4a1d-9b61-855bdda7e4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>dbt_max</th>\n",
       "      <th>dbt_min</th>\n",
       "      <th>dbt_mean</th>\n",
       "      <th>rh_mean</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>28.8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>74.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>30.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>72.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>29.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>77.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>29.6</td>\n",
       "      <td>24.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/2/2009</td>\n",
       "      <td>S102</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>77.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date station_id  dbt_max  dbt_min  dbt_mean  rh_mean  rh_max  rh_min\n",
       "0  1/2/2009       S102     28.8     26.0      27.1     74.6     NaN     NaN\n",
       "1  2/2/2009       S102     30.4     25.0      27.1     72.6     NaN     NaN\n",
       "2  3/2/2009       S102     29.5     25.0      26.6     77.3     NaN     NaN\n",
       "3  4/2/2009       S102     29.6     24.9      26.5     79.6     NaN     NaN\n",
       "4  5/2/2009       S102     30.0     25.2      27.0     77.9     NaN     NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b2bf9-698b-460a-aaa2-a0dbd21c11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_into_postgresql(df, connection):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Prepare the INSERT query\n",
    "    insert_query = sql.SQL(\"\"\"\n",
    "        INSERT INTO national_analysis.site_release (\n",
    "            postal, sector_id, premise_type, release_date, total_dwelling\n",
    "        ) VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\")\n",
    "\n",
    "    # Iterate over the rows in the DataFrame and insert them into the table\n",
    "    for index, row in df.iterrows():\n",
    "        cursor.execute(insert_query, (\n",
    "            int(row['postal']),\n",
    "            row['sector_id'],\n",
    "            row['premise_type'],\n",
    "            row['release_date'] if pd.notnull(row['release_date']) else None,  # Handle NA dates\n",
    "            int(row['total_dwelling']) if pd.notnull(row['total_dwelling']) else None\n",
    "        ))\n",
    "\n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully into national_analysis.site_release!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e98c033-6f4a-4b1a-98a8-3fbe61761776",
   "metadata": {},
   "source": [
    "## Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b82b7a-4814-4dc3-8f80-e198d3361b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
