{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf74f8-96a9-4f8e-9887-11c10a9362f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Injest Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a4614-9833-4f4d-bd1d-7ef49d038fd5",
   "metadata": {},
   "source": [
    "# 1. Coverage data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fad45-4f96-48cb-a206-35e72d7bcea0",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5133ad1b-7afe-4f25-8aae-05449d46c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Function to read the Excel file\n",
    "def read_excel_file(file_path):\n",
    "    # Read the Excel file using pandas\n",
    "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    return df\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4f61f6a-8627-44b3-9449-598138a78805",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data_home = \"/home/wesley/github/etheleon/national_analysis/data/climate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "22a5f2be-db0c-4fe5-99bb-d38f727f6822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://postgres:Hanjin%4027@localhost/dengue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270a3362-96f5-4ae7-b1a2-0ffefcd6f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_into_postgresql(df, connection):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Prepare the INSERT query\n",
    "    insert_query = sql.SQL(\"\"\"\n",
    "        INSERT INTO national_analysis.site_release (\n",
    "            postal, sector_id, premise_type, release_date, total_dwelling\n",
    "        ) VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\")\n",
    "\n",
    "    # Iterate over the rows in the DataFrame and insert them into the table\n",
    "    for index, row in df.iterrows():\n",
    "        cursor.execute(insert_query, (\n",
    "            int(row['postal']),\n",
    "            row['sector_id'],\n",
    "            row['premise_type'],\n",
    "            row['release_date'] if pd.notnull(row['release_date']) else None,  # Handle NA dates\n",
    "            int(row['total_dwelling']) if pd.notnull(row['total_dwelling']) else None\n",
    "        ))\n",
    "\n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully into national_analysis.site_release!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14adb4f0-f4e4-4ac0-8846-2b4221086f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_site_home = \"/home/wesley/github/etheleon/national_analysis/data/release_site\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a4dc5bc-cd8d-439f-be49-0f9a104e2abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdb.xlsx  landed.xlsx  rct.xlsx\n"
     ]
    }
   ],
   "source": [
    "! ls $release_site_home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada3777-46db-4291-a894-51f75eaebeef",
   "metadata": {},
   "source": [
    "# Create connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "af133bdd-874e-47f5-ba90-d2da544c3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'dbname': 'dengue',\n",
    "    'user': 'postgres',\n",
    "    'password': 'Hanjin@27',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "connection = psycopg2.connect(**db_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c435f3-4ef2-4839-bd75-eb255a27dfe1",
   "metadata": {},
   "source": [
    "## HDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4965c64a-e8ef-4c06-b9e8-c83694f22565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HDB_RESIDENTIAL'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdb_df = read_excel_file(os.path.join(release_site_home, \"hdb.xlsx\"))\n",
    "hdb_df[\"PremiseType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c28fa18-a28c-440e-84e0-34669bd510b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal</th>\n",
       "      <th>premise_type</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>total_dwelling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>520103</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL332</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>520104</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL332</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>520140</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL306</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>520143</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL306</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520202</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL119</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>391092</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>392091</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>391091</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>391090</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>392090</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL848</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2782 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      postal     premise_type sector_id release_date  total_dwelling\n",
       "0     520103  HDB_RESIDENTIAL     FL332   2020-02-17             126\n",
       "1     520104  HDB_RESIDENTIAL     FL332   2020-02-17             119\n",
       "2     520140  HDB_RESIDENTIAL     FL306   2019-11-04             114\n",
       "3     520143  HDB_RESIDENTIAL     FL306   2019-11-04              80\n",
       "4     520202  HDB_RESIDENTIAL     FL119   2020-02-17             140\n",
       "...      ...              ...       ...          ...             ...\n",
       "2777  391092  HDB_RESIDENTIAL     FL848   2024-02-28             180\n",
       "2778  392091  HDB_RESIDENTIAL     FL848   2024-02-28             182\n",
       "2779  391091  HDB_RESIDENTIAL     FL848   2024-02-28             201\n",
       "2780  391090  HDB_RESIDENTIAL     FL848   2024-02-28             204\n",
       "2781  392090  HDB_RESIDENTIAL     FL848   2024-02-28             187\n",
       "\n",
       "[2782 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdb_df_short = (\n",
    "    hdb_df[\n",
    "        [\"Postal\", \"PremiseType\", \"Sector_ID\", \n",
    "         \"FirstSustainedReleaseDate_Postal\",\n",
    "         \"TotalDwelling\"]]\n",
    "    .rename(columns={\n",
    "    'Postal': 'postal',\n",
    "    'PremiseType': 'premise_type',\n",
    "    'Sector_ID': 'sector_id',\n",
    "    'FirstSustainedReleaseDate_Postal': 'release_date',\n",
    "    'TotalDwelling': 'total_dwelling'\n",
    "    })\n",
    ")\n",
    "hdb_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc6e9fa7-9d39-455d-9bf0-b6b361f58821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into national_analysis.site_release!\n"
     ]
    }
   ],
   "source": [
    "insert_data_into_postgresql(hdb_df_short, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9fcf6185-f622-4359-aa62-a5148391a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebdc90-07b0-4006-8e18-071c7982a7b3",
   "metadata": {},
   "source": [
    "There are sites where wolbachia has never been released before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa741837-02d7-4beb-bb84-be0d57a5ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost/dengue\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>postal</th>\n",
       "            <th>sector_id</th>\n",
       "            <th>premise_type</th>\n",
       "            <th>release_date</th>\n",
       "            <th>total_dwelling</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>681801</td>\n",
       "            <td>FL767</td>\n",
       "            <td>HDB_RESIDENTIAL</td>\n",
       "            <td>None</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(681801, 'FL767', 'HDB_RESIDENTIAL', None, 96)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "select * from national_analysis.site_release where postal = 681801"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b983b9-0bd6-4504-be70-533e0f412a52",
   "metadata": {},
   "source": [
    "## Landed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4ec97fa-8fac-4b81-a2c0-e4f5064ce7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LANDED_RESIDENTIAL'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landed_df = read_excel_file(os.path.join(release_site_home, \"landed.xlsx\"))\n",
    "landed_df[\"PremiseType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dce429b-47d1-4f16-aab3-e32a7d97336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postal</th>\n",
       "      <th>Block</th>\n",
       "      <th>PremiseType</th>\n",
       "      <th>RO</th>\n",
       "      <th>Constituency</th>\n",
       "      <th>EHISectorID</th>\n",
       "      <th>Sector_ID</th>\n",
       "      <th>StudyArea</th>\n",
       "      <th>ReleaseSiteSincePhase2.2</th>\n",
       "      <th>FirstReleaseDate_Postal</th>\n",
       "      <th>...</th>\n",
       "      <th>FirstReleaseEYEW_Sector</th>\n",
       "      <th>StartRelease_FullSector</th>\n",
       "      <th>StartRelease_SectorAdjusted</th>\n",
       "      <th>TotalDwelling</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>FirstSustainedReleaseDate_Postal</th>\n",
       "      <th>FirstSustainedReleaseEmonth_Postal</th>\n",
       "      <th>FirstSustainedReleaseEyear.Eweek_Postal</th>\n",
       "      <th>Num_Gravitrap_deployed_2022EW17/18</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415800</td>\n",
       "      <td>14A</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415801</td>\n",
       "      <td>14B</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415899</td>\n",
       "      <td>396</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO226</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416507</td>\n",
       "      <td>1</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>416508</td>\n",
       "      <td>2</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>277080</td>\n",
       "      <td>20</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15776</th>\n",
       "      <td>277261</td>\n",
       "      <td>6</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15777</th>\n",
       "      <td>277321</td>\n",
       "      <td>61</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>276844</td>\n",
       "      <td>9</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15779</th>\n",
       "      <td>277003</td>\n",
       "      <td>11</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>NWRO</td>\n",
       "      <td>Ulu Pandan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO92</td>\n",
       "      <td>Holland_landed</td>\n",
       "      <td>Holland_landed_2024EW08_Feb</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15780 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Postal Block         PremiseType    RO         Constituency  \\\n",
       "0      415800   14A  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "1      415801   14B  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "2      415899   396  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "3      416507     1  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "4      416508     2  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee   \n",
       "...       ...   ...                 ...   ...                  ...   \n",
       "15775  277080    20  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "15776  277261     6  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "15777  277321    61  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "15778  276844     9  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "15779  277003    11  LANDED_RESIDENTIAL  NWRO           Ulu Pandan   \n",
       "\n",
       "       EHISectorID Sector_ID            StudyArea  \\\n",
       "0              NaN     CO203  MarineParade_landed   \n",
       "1              NaN     CO203  MarineParade_landed   \n",
       "2              NaN     CO226  MarineParade_landed   \n",
       "3              NaN     CO203  MarineParade_landed   \n",
       "4              NaN     CO203  MarineParade_landed   \n",
       "...            ...       ...                  ...   \n",
       "15775          NaN      CO92       Holland_landed   \n",
       "15776          NaN      CO92       Holland_landed   \n",
       "15777          NaN      CO92       Holland_landed   \n",
       "15778          NaN      CO92       Holland_landed   \n",
       "15779          NaN      CO92       Holland_landed   \n",
       "\n",
       "               ReleaseSiteSincePhase2.2 FirstReleaseDate_Postal  ...  \\\n",
       "0      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "1      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "2      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "3      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "4      MarineParade_landed_2022EW17_Apr              2022-04-30  ...   \n",
       "...                                 ...                     ...  ...   \n",
       "15775       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "15776       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "15777       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "15778       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "15779       Holland_landed_2024EW08_Feb                     NaT  ...   \n",
       "\n",
       "       FirstReleaseEYEW_Sector  StartRelease_FullSector  \\\n",
       "0                      2022.17                  2022.17   \n",
       "1                      2022.17                  2022.17   \n",
       "2                      2022.17                  2022.17   \n",
       "3                      2022.17                  2022.17   \n",
       "4                      2022.17                  2022.17   \n",
       "...                        ...                      ...   \n",
       "15775                      NaN                      NaN   \n",
       "15776                      NaN                      NaN   \n",
       "15777                      NaN                      NaN   \n",
       "15778                      NaN                      NaN   \n",
       "15779                      NaN                      NaN   \n",
       "\n",
       "       StartRelease_SectorAdjusted  TotalDwelling  DATA_TYPE  \\\n",
       "0                          2022.17              1       extg   \n",
       "1                          2022.17              1       extg   \n",
       "2                          2022.17              1       extg   \n",
       "3                          2022.17              1       extg   \n",
       "4                          2022.17              1       extg   \n",
       "...                            ...            ...        ...   \n",
       "15775                          NaN              1       extg   \n",
       "15776                          NaN              1       extg   \n",
       "15777                          NaN              1       extg   \n",
       "15778                          NaN              1       extg   \n",
       "15779                          NaN              1       extg   \n",
       "\n",
       "       FirstSustainedReleaseDate_Postal FirstSustainedReleaseEmonth_Postal  \\\n",
       "0                            2022-04-30                                Apr   \n",
       "1                            2022-04-30                                Apr   \n",
       "2                            2022-04-30                                Apr   \n",
       "3                            2022-04-30                                Apr   \n",
       "4                            2022-04-30                                Apr   \n",
       "...                                 ...                                ...   \n",
       "15775                               NaT                                NaN   \n",
       "15776                               NaT                                NaN   \n",
       "15777                               NaT                                NaN   \n",
       "15778                               NaT                                NaN   \n",
       "15779                               NaT                                NaN   \n",
       "\n",
       "      FirstSustainedReleaseEyear.Eweek_Postal  \\\n",
       "0                                     2022.17   \n",
       "1                                     2022.17   \n",
       "2                                     2022.17   \n",
       "3                                     2022.17   \n",
       "4                                     2022.17   \n",
       "...                                       ...   \n",
       "15775                                     NaN   \n",
       "15776                                     NaN   \n",
       "15777                                     NaN   \n",
       "15778                                     NaN   \n",
       "15779                                     NaN   \n",
       "\n",
       "      Num_Gravitrap_deployed_2022EW17/18  Remarks  \n",
       "0                                    0.0      NaN  \n",
       "1                                    0.0      NaN  \n",
       "2                                    0.0      NaN  \n",
       "3                                    0.0      NaN  \n",
       "4                                    1.0      NaN  \n",
       "...                                  ...      ...  \n",
       "15775                                NaN      NaN  \n",
       "15776                                NaN      NaN  \n",
       "15777                                NaN      NaN  \n",
       "15778                                NaN      NaN  \n",
       "15779                                NaN      NaN  \n",
       "\n",
       "[15780 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9540767e-3087-47c6-9e8d-ee0b86817028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal</th>\n",
       "      <th>premise_type</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>total_dwelling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415800</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO203</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415801</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO203</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415899</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO226</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416507</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO203</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>416508</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO203</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>277080</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15776</th>\n",
       "      <td>277261</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15777</th>\n",
       "      <td>277321</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15778</th>\n",
       "      <td>276844</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15779</th>\n",
       "      <td>277003</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>CO92</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15780 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       postal        premise_type sector_id release_date  total_dwelling\n",
       "0      415800  LANDED_RESIDENTIAL     CO203   2022-04-30               1\n",
       "1      415801  LANDED_RESIDENTIAL     CO203   2022-04-30               1\n",
       "2      415899  LANDED_RESIDENTIAL     CO226   2022-04-30               1\n",
       "3      416507  LANDED_RESIDENTIAL     CO203   2022-04-30               1\n",
       "4      416508  LANDED_RESIDENTIAL     CO203   2022-04-30               1\n",
       "...       ...                 ...       ...          ...             ...\n",
       "15775  277080  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "15776  277261  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "15777  277321  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "15778  276844  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "15779  277003  LANDED_RESIDENTIAL      CO92          NaT               1\n",
       "\n",
       "[15780 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landed_df_short = (\n",
    "    landed_df[\n",
    "        [\"Postal\", \"PremiseType\", \"Sector_ID\", \n",
    "         \"FirstSustainedReleaseDate_Postal\",\n",
    "         \"TotalDwelling\"]]\n",
    "    .rename(columns={\n",
    "    'Postal': 'postal',\n",
    "    'PremiseType': 'premise_type',\n",
    "    'Sector_ID': 'sector_id',\n",
    "    'FirstSustainedReleaseDate_Postal': 'release_date',\n",
    "    'TotalDwelling': 'total_dwelling'\n",
    "    })\n",
    ")\n",
    "landed_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91f8bb25-9842-44d1-ace2-1b2b7abf263c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postal</th>\n",
       "      <th>Block</th>\n",
       "      <th>PremiseType</th>\n",
       "      <th>RO</th>\n",
       "      <th>Constituency</th>\n",
       "      <th>EHISectorID</th>\n",
       "      <th>Sector_ID</th>\n",
       "      <th>StudyArea</th>\n",
       "      <th>ReleaseSiteSincePhase2.2</th>\n",
       "      <th>FirstReleaseDate_Postal</th>\n",
       "      <th>...</th>\n",
       "      <th>FirstReleaseEYEW_Sector</th>\n",
       "      <th>StartRelease_FullSector</th>\n",
       "      <th>StartRelease_SectorAdjusted</th>\n",
       "      <th>TotalDwelling</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>FirstSustainedReleaseDate_Postal</th>\n",
       "      <th>FirstSustainedReleaseEmonth_Postal</th>\n",
       "      <th>FirstSustainedReleaseEyear.Eweek_Postal</th>\n",
       "      <th>Num_Gravitrap_deployed_2022EW17/18</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>418934</td>\n",
       "      <td>14</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>418934</td>\n",
       "      <td>14A</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>418934</td>\n",
       "      <td>14B</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>418934</td>\n",
       "      <td>14C</td>\n",
       "      <td>LANDED_RESIDENTIAL</td>\n",
       "      <td>SERO</td>\n",
       "      <td>Kembangan-Chai Chee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO203</td>\n",
       "      <td>MarineParade_landed</td>\n",
       "      <td>MarineParade_landed_2022EW17_Apr</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>...</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>1</td>\n",
       "      <td>extg</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2022.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Postal Block         PremiseType    RO         Constituency  EHISectorID  \\\n",
       "165  418934    14  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee          NaN   \n",
       "166  418934   14A  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee          NaN   \n",
       "167  418934   14B  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee          NaN   \n",
       "168  418934   14C  LANDED_RESIDENTIAL  SERO  Kembangan-Chai Chee          NaN   \n",
       "\n",
       "    Sector_ID            StudyArea          ReleaseSiteSincePhase2.2  \\\n",
       "165     CO203  MarineParade_landed  MarineParade_landed_2022EW17_Apr   \n",
       "166     CO203  MarineParade_landed  MarineParade_landed_2022EW17_Apr   \n",
       "167     CO203  MarineParade_landed  MarineParade_landed_2022EW17_Apr   \n",
       "168     CO203  MarineParade_landed  MarineParade_landed_2022EW17_Apr   \n",
       "\n",
       "    FirstReleaseDate_Postal  ...  FirstReleaseEYEW_Sector  \\\n",
       "165              2022-04-30  ...                  2022.17   \n",
       "166              2022-04-30  ...                  2022.17   \n",
       "167              2022-04-30  ...                  2022.17   \n",
       "168              2022-04-30  ...                  2022.17   \n",
       "\n",
       "     StartRelease_FullSector  StartRelease_SectorAdjusted  TotalDwelling  \\\n",
       "165                  2022.17                      2022.17              1   \n",
       "166                  2022.17                      2022.17              1   \n",
       "167                  2022.17                      2022.17              1   \n",
       "168                  2022.17                      2022.17              1   \n",
       "\n",
       "     DATA_TYPE  FirstSustainedReleaseDate_Postal  \\\n",
       "165       extg                        2022-04-30   \n",
       "166       extg                        2022-04-30   \n",
       "167       extg                        2022-04-30   \n",
       "168       extg                        2022-04-30   \n",
       "\n",
       "    FirstSustainedReleaseEmonth_Postal  \\\n",
       "165                                Apr   \n",
       "166                                Apr   \n",
       "167                                Apr   \n",
       "168                                Apr   \n",
       "\n",
       "    FirstSustainedReleaseEyear.Eweek_Postal  \\\n",
       "165                                 2022.17   \n",
       "166                                 2022.17   \n",
       "167                                 2022.17   \n",
       "168                                 2022.17   \n",
       "\n",
       "    Num_Gravitrap_deployed_2022EW17/18  Remarks  \n",
       "165                                0.0      NaN  \n",
       "166                                0.0      NaN  \n",
       "167                                0.0      NaN  \n",
       "168                                0.0      NaN  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landed_df.query(\"Postal == 418934\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f3ab64f-ebf3-444c-8b32-7a6c47c51f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "landed_df_short_agg = landed_df_short.groupby(\n",
    "    ['postal', 'premise_type', 'sector_id', 'release_date'])['total_dwelling'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e625d56-1569-4e9f-bae9-a5e270b1c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into national_analysis.site_release!\n"
     ]
    }
   ],
   "source": [
    "insert_data_into_postgresql(landed_df_short_agg, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24a1bd09-34d1-41a9-96c2-b4d943d12e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost/dengue\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>postal</th>\n",
       "            <th>sector_id</th>\n",
       "            <th>premise_type</th>\n",
       "            <th>release_date</th>\n",
       "            <th>total_dwelling</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>418934</td>\n",
       "            <td>CO203</td>\n",
       "            <td>LANDED_RESIDENTIAL</td>\n",
       "            <td>2022-04-30</td>\n",
       "            <td>4</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(418934, 'CO203', 'LANDED_RESIDENTIAL', datetime.date(2022, 4, 30), 4)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "select * from national_analysis.site_release where postal = 418934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc93998c-d507-4a2a-af89-3afab996b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5b9e954-bb13-4754-94d7-33da12bb7dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HDB_RESIDENTIAL'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rct_df = read_excel_file(os.path.join(release_site_home, \"rct.xlsx\"))\n",
    "rct_df[\"PremiseType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e97d354c-ebc8-4a4c-a853-26ed9073b554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal</th>\n",
       "      <th>premise_type</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>total_dwelling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360081</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360082</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360083</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370019</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>370020</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL20</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>670608</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>670609</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>670610</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>670611</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>670612</td>\n",
       "      <td>HDB_RESIDENTIAL</td>\n",
       "      <td>FL727</td>\n",
       "      <td>NaT</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2259 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      postal     premise_type sector_id release_date  total_dwelling\n",
       "0     360081  HDB_RESIDENTIAL      FL20   2022-07-29             130\n",
       "1     360082  HDB_RESIDENTIAL      FL20   2022-07-29              94\n",
       "2     360083  HDB_RESIDENTIAL      FL20   2022-07-29              93\n",
       "3     370019  HDB_RESIDENTIAL      FL20   2022-07-29             120\n",
       "4     370020  HDB_RESIDENTIAL      FL20   2022-07-29             120\n",
       "...      ...              ...       ...          ...             ...\n",
       "2254  670608  HDB_RESIDENTIAL     FL727          NaT              80\n",
       "2255  670609  HDB_RESIDENTIAL     FL727          NaT             172\n",
       "2256  670610  HDB_RESIDENTIAL     FL727          NaT              80\n",
       "2257  670611  HDB_RESIDENTIAL     FL727          NaT             170\n",
       "2258  670612  HDB_RESIDENTIAL     FL727          NaT             123\n",
       "\n",
       "[2259 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rct_df_short = (\n",
    "    rct_df[\n",
    "        [\"Postal\", \"PremiseType\", \"Sector_ID\", \n",
    "         \"FirstSustainedReleaseDate_Postal\",\n",
    "         \"TotalDwelling\"]]\n",
    "    .rename(columns={\n",
    "    'Postal': 'postal',\n",
    "    'PremiseType': 'premise_type',\n",
    "    'Sector_ID': 'sector_id',\n",
    "    'FirstSustainedReleaseDate_Postal': 'release_date',\n",
    "    'TotalDwelling': 'total_dwelling'\n",
    "    })\n",
    ")\n",
    "rct_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4606a4ea-6b3a-46e7-aa90-716746d3a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into national_analysis.site_release!\n"
     ]
    }
   ],
   "source": [
    "insert_data_into_postgresql(rct_df_short, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3d2542f-e98f-4f3d-8837-98fa0a8effef",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47745a67-2470-4af3-a363-bc8f7d41e34d",
   "metadata": {},
   "source": [
    "# 2. Climate data\n",
    "\n",
    "In the paper, only two climate features were used \n",
    "* `max_t_scale_12_wk_avg_0`\n",
    "* `days_no_rain_12_wk_total_0`\n",
    "\n",
    "\n",
    "There exists two types of files `DBT_RH` which stands for Dry Bulb Temperature (DBT) + Relative Humidity (RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e322e43-a62b-4b74-b053-8a705b338fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " forecast\n",
      "'Weekly DBT_RH 20221226-20230101.csv'\n",
      "'Weekly DBT_RH 20230102-20230108.csv'\n",
      "'Weekly DBT_RH 20230109-20230115.csv'\n",
      "'Weekly DBT_RH 20230116-20230122.csv'\n",
      "'Weekly DBT_RH 20230123-20230129.csv'\n",
      "'Weekly DBT_RH 20230130-20230205.csv'\n",
      "'Weekly DBT_RH 20230206-20230212.csv'\n",
      "'Weekly DBT_RH 20230213-20230219.csv'\n",
      "'Weekly DBT_RH 20230220-20230226.csv'\n",
      "'Weekly DBT_RH 20230227-20230305.csv'\n",
      "'Weekly DBT_RH 20230306-20230312.csv'\n",
      "'Weekly DBT_RH 20230313-20230319.csv'\n",
      "'Weekly DBT_RH 20230320-20230326.csv'\n",
      "'Weekly DBT_RH 20230327-20230402.csv'\n",
      "'Weekly DBT_RH 20230403-20230409.csv'\n",
      "'Weekly DBT_RH 20230410-20230416.csv'\n",
      "'Weekly DBT_RH 20230417-20230423.csv'\n",
      "'Weekly DBT_RH 20230424-20230430.csv'\n",
      "'Weekly DBT_RH 20230501-20230507.csv'\n",
      "'Weekly DBT_RH 20230508-20230514.csv'\n",
      "'Weekly DBT_RH 20230515-20230521.csv'\n",
      "'Weekly DBT_RH 20230522-20230528.csv'\n",
      "'Weekly DBT_RH 20230529-20230604_amended.csv'\n",
      "'Weekly DBT_RH 20230605-20230611.csv'\n",
      "'Weekly DBT_RH 20230612-20230618.csv'\n",
      "'Weekly DBT_RH 20230619-20230625.csv'\n",
      "'Weekly DBT_RH 20230626-20230702.csv'\n",
      "'Weekly DBT_RH 20230703-20230709.csv'\n",
      "'Weekly DBT_RH 20230710-20230716.csv'\n",
      "'Weekly DBT_RH 20230717-20230723.csv'\n",
      "'Weekly DBT_RH 20230724-20230730.csv'\n",
      "'Weekly DBT_RH 20230731-20230806.csv'\n",
      "'Weekly DBT_RH 20230807-20230813.csv'\n",
      "'Weekly DBT_RH 20230814-20230820.csv'\n",
      "'Weekly DBT_RH 20230821-20230827.csv'\n",
      "'Weekly DBT_RH 20230828-20230903.csv'\n",
      "'Weekly DBT_RH 20230904-20230910.csv'\n",
      "'Weekly DBT_RH 20230911-20230917.csv'\n",
      "'Weekly DBT_RH 20230918-20230924.csv'\n",
      "'Weekly DBT_RH 20230925-20231001.csv'\n",
      "'Weekly DBT_RH 20231002-20231008.csv'\n",
      "'Weekly DBT_RH 20231009-20231015.csv'\n",
      "'Weekly DBT_RH 20231016-20231022.csv'\n",
      "'Weekly DBT_RH 20231023-20231029.csv'\n",
      "'Weekly DBT_RH 20231030-20231105.csv'\n",
      "'Weekly DBT_RH 20231106-20231112.csv'\n",
      "'Weekly DBT_RH 20231113-20231119.csv'\n",
      "'Weekly DBT_RH 20231120-20231126.csv'\n",
      "'Weekly DBT_RH 20231127-20231203.csv'\n",
      "'Weekly DBT_RH 20231204-20231210.csv'\n",
      "'Weekly DBT_RH 20231211-20231217.csv'\n",
      "'Weekly DBT_RH 20231218-20231224.csv'\n",
      "'Weekly DBT_RH 20231225-20231231.csv'\n",
      "'Weekly Rain 20221226-20230101.csv'\n",
      "'Weekly Rain 20230102-20230108.csv'\n",
      "'Weekly Rain 20230109-20230115.csv'\n",
      "'Weekly Rain 20230116-20230122.csv'\n",
      "'Weekly Rain 20230123-20230129.csv'\n",
      "'Weekly Rain 20230130-20230205.csv'\n",
      "'Weekly Rain 20230206-20230212.csv'\n",
      "'Weekly Rain 20230213-20230219.csv'\n",
      "'Weekly Rain 20230220-20230226.csv'\n",
      "'Weekly Rain 20230227-20230305.csv'\n",
      "'Weekly Rain 20230306-20230312.csv'\n",
      "'Weekly Rain 20230313-20230319.csv'\n",
      "'Weekly Rain 20230320-20230326.csv'\n",
      "'Weekly Rain 20230327-20230402.csv'\n",
      "'Weekly Rain 20230403-20230409.csv'\n",
      "'Weekly Rain 20230410-20230416.csv'\n",
      "'Weekly Rain 20230417-20230423.csv'\n",
      "'Weekly Rain 20230424-20230430.csv'\n",
      "'Weekly Rain 20230501-20230507.csv'\n",
      "'Weekly Rain 20230508-20230514.csv'\n",
      "'Weekly Rain 20230515-20230521.csv'\n",
      "'Weekly Rain 20230522-20230528.csv'\n",
      "'Weekly Rain 20230529-20230604.csv'\n",
      "'Weekly Rain 20230605-20230611.csv'\n",
      "'Weekly Rain 20230612-20230618.csv'\n",
      "'Weekly Rain 20230619-20230625.csv'\n",
      "'Weekly Rain 20230626-20230702.csv'\n",
      "'Weekly Rain 20230703-20230709.csv'\n",
      "'Weekly Rain 20230710-20230716.csv'\n",
      "'Weekly Rain 20230717-20230723.csv'\n",
      "'Weekly Rain 20230724-20230730.csv'\n",
      "'Weekly Rain 20230731-20230806.csv'\n",
      "'Weekly Rain 20230807-20230813.csv'\n",
      "'Weekly Rain 20230814-20230820.csv'\n",
      "'Weekly Rain 20230821-20230827.csv'\n",
      "'Weekly Rain 20230828-20230903.csv'\n",
      "'Weekly Rain 20230904-20230910.csv'\n",
      "'Weekly Rain 20230911-20230917.csv'\n",
      "'Weekly Rain 20230918-20230924.csv'\n",
      "'Weekly Rain 20230925-20231001.csv'\n",
      "'Weekly Rain 20231002-20231008.csv'\n",
      "'Weekly Rain 20231009-20231015.csv'\n",
      "'Weekly Rain 20231016-20231022.csv'\n",
      "'Weekly Rain 20231023-20231029.csv'\n",
      "'Weekly Rain 20231030-20231105.csv'\n",
      "'Weekly Rain 20231106-20231112.csv'\n",
      "'Weekly Rain 20231113-20231119.csv'\n",
      "'Weekly Rain 20231120-20231126.csv'\n",
      "'Weekly Rain 20231127-20231203.csv'\n",
      "'Weekly Rain 20231204-20231210.csv'\n",
      "'Weekly Rain 20231211-20231217.csv'\n",
      "'Weekly Rain 20231218-20231224.csv'\n",
      "'Weekly Rain 20231225-20231231.csv'\n"
     ]
    }
   ],
   "source": [
    "! ls /home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a555da08-ca93-4992-8d02-3b5f0a6ba7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def read_yearly(root_dir: str):\n",
    "    csv_files = glob(os.path.join(root_dir, 'Weekly DBT_RH*.csv'))\n",
    "    print(csv_files)\n",
    "    return pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a27dda-5db8-46f7-b993-879ee6a7b8c6",
   "metadata": {},
   "source": [
    "`dbt` - Dry bulb temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2a2b74ea-252b-42e7-a6a3-e19eff11048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_date_with_filename(date_str, filename):\n",
    "    \"\"\"\n",
    "    Try to parse a date string in either day/month/year or month/day/year format based on the file name's date range.\n",
    "    Return the parsed date if it falls within the file's date range; otherwise, return pd.NaT.\n",
    "    \"\"\"\n",
    "    # Extract the date range from the file name (e.g., '20230109-20230115')\n",
    "    match = re.search(r'(\\d{8})-(\\d{8})', filename)\n",
    "    \n",
    "    if match:\n",
    "        # Extract start and end dates from the file name\n",
    "        start_date = pd.to_datetime(match.group(1), format='%Y%m%d')\n",
    "        end_date = pd.to_datetime(match.group(2), format='%Y%m%d')\n",
    "\n",
    "        # Try parsing the date string with both formats\n",
    "        try:\n",
    "            # Try day/month/year format\n",
    "            date_dmy = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            date_dmy = pd.NaT\n",
    "\n",
    "        try:\n",
    "            # Try month/day/year format\n",
    "            date_mdy = pd.to_datetime(date_str, format='%m/%d/%Y')\n",
    "        except ValueError:\n",
    "            date_mdy = pd.NaT\n",
    "\n",
    "        # Check if either parsed date falls within the start and end dates\n",
    "        if pd.notna(date_dmy) and start_date <= date_dmy <= end_date:\n",
    "            return date_dmy.strftime('%Y-%m-%d')  \n",
    "        elif pd.notna(date_mdy) and start_date <= date_mdy <= end_date:\n",
    "            return date_mdy.strftime('%Y-%m-%d')  \n",
    "        else:\n",
    "            return pd.NaT  # Return NaT if neither date is valid or in range\n",
    "    else:\n",
    "        return pd.NaT  # Return NaT if no date range is found in the filename\n",
    "\n",
    "def read_dbt_rh(root_dir: str):\n",
    "    # Define the columns you want to standardize and map\n",
    "    column_mapping = {\n",
    "        'stationcode': 'station_id',\n",
    "        'id_station': 'station_id',\n",
    "        'date': 'date',\n",
    "        'dateasia/singapore(+0800)': 'date',\n",
    "        'maxdbt': 'dbt_max',\n",
    "        'mindbt': 'dbt_min',\n",
    "        'meandbt': 'dbt_mean',\n",
    "        'maxrh': 'rh_max',\n",
    "        'minrh': 'rh_min',\n",
    "        'meanrh': 'rh_mean'\n",
    "    }\n",
    "\n",
    "    # Define standard columns after renaming\n",
    "    standard_columns = [\n",
    "        'date', 'station_id', 'dbt_max', 'dbt_min', 'dbt_mean', 'rh_max', 'rh_min', 'rh_mean'\n",
    "    ]\n",
    "    \n",
    "    # Find all CSV files matching the pattern\n",
    "    csv_files = glob(os.path.join(root_dir, 'Weekly DBT_RH*.csv'))\n",
    "    # for file in csv_files:\n",
    "    #     print(file)\n",
    "    \n",
    "    # Create an empty list to store DataFrames\n",
    "    df_list = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        # Read each CSV file\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Normalize column names\n",
    "        df.columns = [col.strip().lower().replace(\" \", \"\").replace('\"', '') for col in df.columns]\n",
    "        \n",
    "        # Rename columns based on the new mapping\n",
    "        df.rename(columns=column_mapping, inplace=True)\n",
    "        \n",
    "        # Filter out the columns that match the standard columns\n",
    "        df_filtered = df[[col for col in standard_columns if col in df.columns]]\n",
    "        \n",
    "        # Encode timezone in the 'date' column\n",
    "        if 'date' in df_filtered.columns:\n",
    "            df_filtered['date'] = df_filtered['date'].apply(lambda x: parse_date_with_filename(x, file))\n",
    "            \n",
    "\n",
    "        # Append the filtered DataFrame to the list\n",
    "        df_list.append(df_filtered)\n",
    "    \n",
    "    # Concatenate all DataFrames into one\n",
    "    df_final = pd.concat(df_list, ignore_index=True)\n",
    "    df_final['date'] = pd.to_datetime(df_final['date'], errors='coerce')\n",
    "    # df_final['date'] = df_final['date'].dt.tz_localize('Asia/Singapore')\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ccbd4907-42b7-45ee-9d45-4576ee197317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/3914993196.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(lambda x: parse_date_with_filename(x, file))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>dbt_max</th>\n",
       "      <th>dbt_min</th>\n",
       "      <th>dbt_mean</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_min</th>\n",
       "      <th>rh_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>S102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>S109</td>\n",
       "      <td>34.4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>90.9</td>\n",
       "      <td>47.2</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>S60</td>\n",
       "      <td>33.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>88.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>S116</td>\n",
       "      <td>32.2</td>\n",
       "      <td>27.5</td>\n",
       "      <td>29.3</td>\n",
       "      <td>89.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>S44</td>\n",
       "      <td>33.1</td>\n",
       "      <td>23.2</td>\n",
       "      <td>27.8</td>\n",
       "      <td>97.4</td>\n",
       "      <td>55.4</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6652</th>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>S115</td>\n",
       "      <td>31.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>28.6</td>\n",
       "      <td>86.7</td>\n",
       "      <td>62.3</td>\n",
       "      <td>77.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6653</th>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>S23</td>\n",
       "      <td>33.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>61.8</td>\n",
       "      <td>84.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6654</th>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>S104</td>\n",
       "      <td>33.2</td>\n",
       "      <td>24.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>89.9</td>\n",
       "      <td>56.3</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>S24</td>\n",
       "      <td>32.2</td>\n",
       "      <td>25.3</td>\n",
       "      <td>28.5</td>\n",
       "      <td>92.9</td>\n",
       "      <td>58.4</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6656</th>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>S106</td>\n",
       "      <td>33.4</td>\n",
       "      <td>24.2</td>\n",
       "      <td>28.1</td>\n",
       "      <td>94.1</td>\n",
       "      <td>57.2</td>\n",
       "      <td>79.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6657 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date station_id  dbt_max  dbt_min  dbt_mean  rh_max  rh_min  \\\n",
       "0    2023-04-24       S102      NaN      NaN       NaN     NaN     NaN   \n",
       "1    2023-04-24       S109     34.4     26.7      29.7    90.9    47.2   \n",
       "2    2023-04-24        S60     33.9     25.9      29.5    88.2    48.0   \n",
       "3    2023-04-24       S116     32.2     27.5      29.3    89.5    55.7   \n",
       "4    2023-04-24        S44     33.1     23.2      27.8    97.4    55.4   \n",
       "...         ...        ...      ...      ...       ...     ...     ...   \n",
       "6652 2023-08-27       S115     31.8     25.8      28.6    86.7    62.3   \n",
       "6653 2023-08-27        S23     33.1     24.0      28.1   100.0    61.8   \n",
       "6654 2023-08-27       S104     33.2     24.8      28.4    89.9    56.3   \n",
       "6655 2023-08-27        S24     32.2     25.3      28.5    92.9    58.4   \n",
       "6656 2023-08-27       S106     33.4     24.2      28.1    94.1    57.2   \n",
       "\n",
       "      rh_mean  \n",
       "0         NaN  \n",
       "1        71.3  \n",
       "2        72.8  \n",
       "3        78.4  \n",
       "4        83.0  \n",
       "...       ...  \n",
       "6652     77.1  \n",
       "6653     84.7  \n",
       "6654     74.0  \n",
       "6655     77.5  \n",
       "6656     79.8  \n",
       "\n",
       "[6657 rows x 8 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_dbt_rh(os.path.join(climate_data_home, 'weather_2023'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "013c2f8e-7303-4036-baa0-194c2c4098d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-04-24 00:00:00+0800', tz='Asia/Singapore')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "426751b7-4e91-4de0-927d-8e930d9c6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rainfall_data(root_dir: str):\n",
    "    # Define the columns you want to standardize and map for rainfall data\n",
    "    column_mapping = {\n",
    "        'stationcode': 'station_id',\n",
    "        'id_station': 'station_id',\n",
    "        'date': 'date',\n",
    "        'date.singapore...0800.': 'date',\n",
    "        'dateasia/singapore(+0800)': 'date',\n",
    "        'datesingapore(+0800)': 'date',\n",
    "        'dailyrainamount(mm)': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'totalrain': 'rain_amount',\n",
    "        'rainamount': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'rainamount': 'rain_amount',\n",
    "        'dailyrainamount(mm)': 'rain_amount',\n",
    "        'dailyrainamount': 'rain_amount',\n",
    "        'dailyrainamount(mm)': 'rain_amount',\n",
    "        'dailyrainamount': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'rainamount': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'dailyrainamount(mm)': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "        'totalrain': 'rain_amount',\n",
    "        'rainamount(mm)': 'rain_amount',\n",
    "    }\n",
    "\n",
    "    standard_columns = [\n",
    "        'date', 'station_id', 'rain_amount', 'rain_duration'\n",
    "    ]\n",
    "\n",
    "    # Find all CSV files in the directory\n",
    "    # Find all CSV files matching the pattern\n",
    "    csv_files = glob(os.path.join(root_dir, 'Weekly Rain*.csv'))\n",
    "    \n",
    "    for file in csv_files:\n",
    "        if re.search(r\"20221226\", file):\n",
    "            print(file)\n",
    "    \n",
    "    # Create an empty list to store DataFrames\n",
    "    df_list = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        print(file)\n",
    "        # Read each CSV file\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Normalize column names\n",
    "        df.columns = [col.strip().lower().replace(\" \", \"\").replace('\"', '') for col in df.columns]\n",
    "        \n",
    "        # Rename columns based on the new mapping\n",
    "        df.rename(columns=column_mapping, inplace=True)\n",
    "        \n",
    "        # Filter out the columns that match the standard columns\n",
    "        df_filtered = df[[col for col in standard_columns if col in df.columns]]\n",
    "\n",
    "        # # Encode timezone in the 'date' column\n",
    "        if 'date' in df_filtered.columns:\n",
    "            df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
    "\n",
    "        # Append the filtered DataFrame to the list\n",
    "        df_list.append(df_filtered)\n",
    "        # Concatenate all DataFrames into one\n",
    "    return pd.concat(df_list, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9e29fa25-b5f7-419f-be78-ffa63e1bd9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20221226-20230101.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230417-20230423.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230731-20230806.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231016-20231022.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230424-20230430.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230529-20230604.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230220-20230226.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230814-20230820.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230327-20230402.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231002-20231008.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230515-20230521.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230717-20230723.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230605-20230611.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230109-20230115.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230102-20230108.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230410-20230416.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230508-20230514.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231225-20231231.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230626-20230702.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231113-20231119.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20221226-20230101.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230206-20230212.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230904-20230910.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230619-20230625.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230306-20230312.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230130-20230205.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230918-20230924.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231009-20231015.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230213-20230219.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231211-20231217.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230320-20230326.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231120-20231126.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231030-20231105.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230227-20230305.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230522-20230528.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230911-20230917.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231106-20231112.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230828-20230903.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230925-20231001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230710-20230716.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230403-20230409.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231023-20231029.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231218-20231224.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230313-20230319.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230821-20230827.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230501-20230507.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230116-20230122.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231204-20231210.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230807-20230813.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n",
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20231127-20231203.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230612-20230618.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230703-20230709.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230123-20230129.csv\n",
      "/home/wesley/github/etheleon/national_analysis/data/climate/weather_2023/Weekly Rain 20230724-20230730.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/4275496042.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(parse_date) # .dt.tz_localize('Asia/Singapore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>rain_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>S102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>S94</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>S215</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>S130</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>S71</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31796</th>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>S303</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31797</th>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>S61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31798</th>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>S113</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31799</th>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>S106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31800</th>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>S108</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31801 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date station_id  rain_amount\n",
       "0      2023-04-17       S102          NaN\n",
       "1      2023-04-17        S94          2.0\n",
       "2      2023-04-17       S215          1.6\n",
       "3      2023-04-17       S130          5.6\n",
       "4      2023-04-17        S71          1.6\n",
       "...           ...        ...          ...\n",
       "31796  2023-07-30       S303          0.0\n",
       "31797  2023-07-30        S61          NaN\n",
       "31798  2023-07-30       S113          0.4\n",
       "31799  2023-07-30       S106          0.0\n",
       "31800  2023-07-30       S108          1.4\n",
       "\n",
       "[31801 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_rainfall_data(os.path.join(climate_data_home, \"weather_2023\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372ee00-1db3-4d74-8f6f-2f94c0945193",
   "metadata": {},
   "source": [
    "Retry with utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2ea8e447-949e-43bd-ab90-2c34b8d7489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import toml\n",
    "\n",
    "\n",
    "def read_excel_file(file_path, sheet_name=\"Sheet1\"):\n",
    "    # Read the Excel file using pandas\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_db_config(config_file=\"secrets.toml\"):\n",
    "    config = toml.load(config_file)\n",
    "    return config[\"database\"]\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def postgres_connection(config_file=\"secrets.toml\"):\n",
    "    conn = None\n",
    "    try:\n",
    "        # Load the database configuration\n",
    "        config = load_db_config(config_file)\n",
    "\n",
    "        # Establish the PostgreSQL connection using the config\n",
    "        conn = psycopg2.connect(\n",
    "            host=config[\"host\"],\n",
    "            database=config[\"dbname\"],\n",
    "            user=config[\"user\"],\n",
    "            password=config[\"password\"],\n",
    "            port=config.get(\"port\", 5432),  # Use port 5432 if not specified\n",
    "        )\n",
    "        # Provide the connection to the block within 'with'\n",
    "        yield conn\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if conn is not None:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "def parse_date_with_filename(date_str, filename):\n",
    "    \"\"\"\n",
    "    Try to parse a date string in either day/month/year or month/day/year format based on the file name's date range.\n",
    "    Return the parsed date if it falls within the file's date range; otherwise, return pd.NaT.\n",
    "    \"\"\"\n",
    "    # Extract the date range from the file name (e.g., '20230109-20230115')\n",
    "    match = re.search(r\"(\\d{8})-(\\d{8})\", filename)\n",
    "\n",
    "    if match:\n",
    "        # Extract start and end dates from the file name\n",
    "        start_date = pd.to_datetime(match.group(1), format=\"%Y%m%d\")\n",
    "        end_date = pd.to_datetime(match.group(2), format=\"%Y%m%d\")\n",
    "\n",
    "        # Try parsing the date string with both formats\n",
    "        try:\n",
    "            # Try day/month/year format\n",
    "            date_dmy = pd.to_datetime(date_str, format=\"%d/%m/%Y\")\n",
    "        except ValueError:\n",
    "            date_dmy = pd.NaT\n",
    "\n",
    "        try:\n",
    "            # Try month/day/year format\n",
    "            date_mdy = pd.to_datetime(date_str, format=\"%m/%d/%Y\")\n",
    "        except ValueError:\n",
    "            date_mdy = pd.NaT\n",
    "\n",
    "        # Check if either parsed date falls within the start and end dates\n",
    "        if pd.notna(date_dmy) and start_date <= date_dmy <= end_date:\n",
    "            return date_dmy.strftime(\"%Y-%m-%d\")\n",
    "        elif pd.notna(date_mdy) and start_date <= date_mdy <= end_date:\n",
    "            return date_mdy.strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "            return pd.NaT  # Return NaT if neither date is valid or in range\n",
    "    else:\n",
    "        return pd.NaT  # Return NaT if no date range is found in the filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "da03e31c-1830-4399-a311-b37c61b2beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from glob import glob\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def standardize(columns: List[str]) -> List[str]:\n",
    "    \"\"\"Removes space and lowers.\"\"\"\n",
    "    newcols = []\n",
    "    for col in columns:\n",
    "        newcols.append(col.strip().lower().replace(\" \", \"\").replace('\"', \"\"))\n",
    "    return newcols\n",
    "\n",
    "\n",
    "def read_dbt_rh_2009_2021(data_root: str) -> pd.DataFrame:\n",
    "    \"\"\"This function reads temperature data for 2009 to 2021.\"\"\"\n",
    "    df = pd.read_csv(os.path.join(data_root, \"weather_1982_2021\", \"Daily DBT 2009-2021.csv\"))\n",
    "\n",
    "    df.columns = standardize(df.columns.tolist())  # type: ignore\n",
    "    column_mappings = {\n",
    "        \"id_station\": \"station_id\",\n",
    "        \"dateasia/singapore(+0800)\": \"date\",\n",
    "        \"maxdbt\": \"dbt_max\",\n",
    "        \"mindbt\": \"dbt_min\",\n",
    "        \"meandbt\": \"dbt_mean\",\n",
    "        \"meanrh\": \"rh_mean\",\n",
    "    }\n",
    "    df.rename(columns=column_mappings, inplace=True)\n",
    "\n",
    "    expected_columns = [\"rh_max\", \"rh_min\", \"rh_mean\"]\n",
    "    for col in expected_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d/%m/%Y\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_dbt_rh_2022(data_root: str) -> pd.DataFrame:\n",
    "    \"\"\"This function reads temperature data for 2022.\"\"\"\n",
    "    snake_case_names = [\n",
    "        \"station_id\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"day\",\n",
    "        \"dbt_mean\",\n",
    "        \"rh_mean\",\n",
    "        \"dbt_max\",\n",
    "        \"dbt_min\",\n",
    "        \"wind_direction_scalar_mean\",\n",
    "        \"wind_speed_scalar_kts_mean\",\n",
    "        \"wind_direction_max\",\n",
    "        \"wind_speed_kts_max\",\n",
    "    ]\n",
    "    params = {\n",
    "        \"skiprows\": 1,\n",
    "        \"names\": snake_case_names,\n",
    "        \"encoding\":\"ISO-8859-1\",\n",
    "        \"usecols\": snake_case_names[:8]\n",
    "    }\n",
    "    df = pd.concat([\n",
    "        pd.read_csv(os.path.join(data_root, \"weather_2022\", \"Temp 2022.csv\"), **params),\n",
    "        pd.read_csv(os.path.join(data_root, \"weather_2022\", \"Temp 202206.csv\"), **params) \n",
    "    ], ignore_index=True)\n",
    "\n",
    "    expected_columns = [\"rh_max\", \"rh_min\", \"rh_mean\"]\n",
    "\n",
    "    for col in expected_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\n",
    "    df.drop(columns=[\"year\", \"month\", \"day\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_dbt_rh_2023_2024(data_dir: str, year: str) -> pd.DataFrame:\n",
    "    \"\"\"This function reads temperature data for 2023.\"\"\"\n",
    "    column_mapping = {\n",
    "        \"stationcode\": \"station_id\",\n",
    "        \"id_station\": \"station_id\",\n",
    "        \"date\": \"date\",\n",
    "        \"dateasia/singapore(+0800)\": \"date\",\n",
    "        \"maxdbt\": \"dbt_max\",\n",
    "        \"mindbt\": \"dbt_min\",\n",
    "        \"meandbt\": \"dbt_mean\",\n",
    "        \"maxrh\": \"rh_max\",\n",
    "        \"minrh\": \"rh_min\",\n",
    "        \"meanrh\": \"rh_mean\",\n",
    "    }\n",
    "\n",
    "    standard_columns = [\n",
    "        \"date\",\n",
    "        \"station_id\",\n",
    "        \"dbt_max\",\n",
    "        \"dbt_min\",\n",
    "        \"dbt_mean\",\n",
    "        \"rh_max\",\n",
    "        \"rh_min\",\n",
    "        \"rh_mean\",\n",
    "    ]\n",
    "\n",
    "    csv_files = glob(os.path.join(data_dir, year, \"Weekly DBT_RH*.csv\"))\n",
    "    df_list = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df.columns = standardize(df.columns.tolist())  # type: ignore\n",
    "        df.rename(columns=column_mapping, inplace=True)\n",
    "        df_filtered = df[[col for col in standard_columns if col in df.columns]]\n",
    "        if \"date\" in df_filtered.columns:\n",
    "            df_filtered[\"date\"] = df_filtered[\"date\"].apply(\n",
    "                lambda x: parse_date_with_filename(x, file)  # pylint: disable=W0640\n",
    "            )\n",
    "        df_list.append(df_filtered)\n",
    "\n",
    "    df_final = pd.concat(df_list, ignore_index=True)\n",
    "    df_final[\"date\"] = pd.to_datetime(df_final[\"date\"], errors=\"coerce\")\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "24cb18cc-8387-499c-9695-dc3692624b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wesley/github/etheleon/national_analysis/data/climate/'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "70d3d91c-c847-4faf-af24-01ba5d77c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = pd.concat(\n",
    "        [\n",
    "            # read_dbt_rh_2009_2021(climate_data_home),\n",
    "            read_dbt_rh_2022(climate_data_home),\n",
    "            # read_dbt_rh_2023_2024(climate_data_home, \"weather_2023\"),\n",
    "            # read_dbt_rh_2023_2024(climate_data_home, \"weather_2024\"),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c0bcaebc-d3c7-4009-b98f-8f62371f502e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>dbt_mean</th>\n",
       "      <th>rh_mean</th>\n",
       "      <th>dbt_max</th>\n",
       "      <th>dbt_min</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_min</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S06</td>\n",
       "      <td>25.8</td>\n",
       "      <td>87.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S06</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S06</td>\n",
       "      <td>26.1</td>\n",
       "      <td>84.8</td>\n",
       "      <td>31.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S06</td>\n",
       "      <td>26.2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S06</td>\n",
       "      <td>28.1</td>\n",
       "      <td>75.3</td>\n",
       "      <td>34.3</td>\n",
       "      <td>25.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>S80</td>\n",
       "      <td>28.2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>S80</td>\n",
       "      <td>28.3</td>\n",
       "      <td>83.6</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>S80</td>\n",
       "      <td>26.6</td>\n",
       "      <td>91.9</td>\n",
       "      <td>33.2</td>\n",
       "      <td>24.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>S80</td>\n",
       "      <td>28.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>S80</td>\n",
       "      <td>26.9</td>\n",
       "      <td>83.8</td>\n",
       "      <td>30.3</td>\n",
       "      <td>23.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3469 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     station_id  dbt_mean  rh_mean  dbt_max  dbt_min  rh_max  rh_min  \\\n",
       "0           S06      25.8     87.5     31.0     23.4     NaN     NaN   \n",
       "1           S06      24.0     96.4     24.9     23.2     NaN     NaN   \n",
       "2           S06      26.1     84.8     31.6     23.4     NaN     NaN   \n",
       "3           S06      26.2     87.0     32.4     24.1     NaN     NaN   \n",
       "4           S06      28.1     75.3     34.3     25.2     NaN     NaN   \n",
       "...         ...       ...      ...      ...      ...     ...     ...   \n",
       "3464        S80      28.2     85.0     33.0     24.3     NaN     NaN   \n",
       "3465        S80      28.3     83.6     33.3     24.6     NaN     NaN   \n",
       "3466        S80      26.6     91.9     33.2     24.2     NaN     NaN   \n",
       "3467        S80      28.0     82.0     32.6     23.5     NaN     NaN   \n",
       "3468        S80      26.9     83.8     30.3     23.9     NaN     NaN   \n",
       "\n",
       "           date  \n",
       "0    2022-01-01  \n",
       "1    2022-01-02  \n",
       "2    2022-01-03  \n",
       "3    2022-01-04  \n",
       "4    2022-01-05  \n",
       "...         ...  \n",
       "3464 2022-06-26  \n",
       "3465 2022-06-27  \n",
       "3466 2022-06-28  \n",
       "3467 2022-06-29  \n",
       "3468 2022-06-30  \n",
       "\n",
       "[3469 rows x 8 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e566a206-d381-4d1d-88b0-8b4ae066ea7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>dbt_mean</th>\n",
       "      <th>rh_mean</th>\n",
       "      <th>dbt_max</th>\n",
       "      <th>dbt_min</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_min</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>S06</td>\n",
       "      <td>28.3</td>\n",
       "      <td>77.8</td>\n",
       "      <td>32.9</td>\n",
       "      <td>26.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>S06</td>\n",
       "      <td>27.4</td>\n",
       "      <td>82.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>24.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>S06</td>\n",
       "      <td>28.3</td>\n",
       "      <td>77.3</td>\n",
       "      <td>32.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>S06</td>\n",
       "      <td>27.8</td>\n",
       "      <td>81.7</td>\n",
       "      <td>32.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>S06</td>\n",
       "      <td>28.3</td>\n",
       "      <td>78.8</td>\n",
       "      <td>31.4</td>\n",
       "      <td>23.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>S80</td>\n",
       "      <td>28.2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>S80</td>\n",
       "      <td>28.3</td>\n",
       "      <td>83.6</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>S80</td>\n",
       "      <td>26.6</td>\n",
       "      <td>91.9</td>\n",
       "      <td>33.2</td>\n",
       "      <td>24.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>S80</td>\n",
       "      <td>28.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>S80</td>\n",
       "      <td>26.9</td>\n",
       "      <td>83.8</td>\n",
       "      <td>30.3</td>\n",
       "      <td>23.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     station_id  dbt_mean  rh_mean  dbt_max  dbt_min  rh_max  rh_min  \\\n",
       "2870        S06      28.3     77.8     32.9     26.1     NaN     NaN   \n",
       "2871        S06      27.4     82.7     30.7     24.1     NaN     NaN   \n",
       "2872        S06      28.3     77.3     32.4     23.5     NaN     NaN   \n",
       "2873        S06      27.8     81.7     32.6     25.3     NaN     NaN   \n",
       "2874        S06      28.3     78.8     31.4     23.8     NaN     NaN   \n",
       "...         ...       ...      ...      ...      ...     ...     ...   \n",
       "3464        S80      28.2     85.0     33.0     24.3     NaN     NaN   \n",
       "3465        S80      28.3     83.6     33.3     24.6     NaN     NaN   \n",
       "3466        S80      26.6     91.9     33.2     24.2     NaN     NaN   \n",
       "3467        S80      28.0     82.0     32.6     23.5     NaN     NaN   \n",
       "3468        S80      26.9     83.8     30.3     23.9     NaN     NaN   \n",
       "\n",
       "           date  \n",
       "2870 2022-06-02  \n",
       "2871 2022-06-03  \n",
       "2872 2022-06-04  \n",
       "2873 2022-06-05  \n",
       "2874 2022-06-06  \n",
       "...         ...  \n",
       "3464 2022-06-26  \n",
       "3465 2022-06-27  \n",
       "3466 2022-06-28  \n",
       "3467 2022-06-29  \n",
       "3468 2022-06-30  \n",
       "\n",
       "[580 rows x 8 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"date > '2022-06-01'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5926e4-611b-4368-946c-585700c9b91e",
   "metadata": {},
   "source": [
    "## 2022-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2e4fa-047c-4063-abf7-eaeb0ee66311",
   "metadata": {},
   "source": [
    "### Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec30ec-27cb-42bb-a707-8dc85e366520",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531d947-219e-46d8-badd-719e300490bf",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c8213-fa7c-4948-8498-6c3a7b9e59dc",
   "metadata": {},
   "source": [
    "1982 - 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "96b1d410-d5e2-49da-8e31-0f3bbdfb3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_2009_2021_df = pd.read_csv(os.path.join(climate_data_home, \"weather_1982_2021\", \"Daily DBT 2009-2021.csv\"))\n",
    "temperature_2009_2021_df.columns = [col.strip().lower().replace(\" \", \"\").replace('\"', '') for col in temperature_2009_2021_df.columns]\n",
    "temperature_2009_2021_df.rename(columns=  {\n",
    "        \n",
    "        'id_station': 'station_id',\n",
    "        \n",
    "        'dateasia/singapore(+0800)': 'date',\n",
    "        'maxdbt': 'dbt_max',\n",
    "        'mindbt': 'dbt_min',\n",
    "        'meandbt': 'dbt_mean',\n",
    "        'meanrh': 'rh_mean'\n",
    "    }, inplace=True)\n",
    "\n",
    "expected_columns = ['rh_max', 'rh_min', 'rh_mean']\n",
    "\n",
    "# Check if each column exists in the DataFrame, and if not, add it with NaN values\n",
    "for col in expected_columns:\n",
    "    if col not in temperature_2009_2021_df.columns:\n",
    "        temperature_2009_2021_df[col] = np.nan\n",
    "\n",
    "\n",
    "temperature_2009_2021_df['date'] = pd.to_datetime(temperature_2009_2021_df['date'], format='%d/%m/%Y') # .dt.tz_localize('Asia/Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "25880337-da69-4256-9410-5d24c57f5420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2009-02-01\n",
       "1        2009-02-02\n",
       "2        2009-02-03\n",
       "3        2009-02-04\n",
       "4        2009-02-05\n",
       "            ...    \n",
       "137413   2021-12-27\n",
       "137414   2021-12-28\n",
       "137415   2021-12-29\n",
       "137416   2021-12-30\n",
       "137417   2021-12-31\n",
       "Name: date, Length: 137418, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_2009_2021_df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37971a7-5c67-48e4-a916-c861f315541f",
   "metadata": {},
   "source": [
    "2022 is slightly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "15b5362e-2d1b-4b9a-8243-0852498bbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names with max, min, and mean as suffixes\n",
    "snake_case_names = [\n",
    "    \"station\", \"year\", \"month\", \"day\", \"dbt_mean\",\n",
    "    \"rh_mean\", \"dbt_max\", \"dbt_min\",\n",
    "    \"wind_direction_scalar_mean\", \"wind_speed_scalar_kts_mean\",\n",
    "    \"wind_direction_max\", \"wind_speed_kts_max\"\n",
    "]\n",
    "\n",
    "# Read the CSV file, skipping the first row and using the custom column names\n",
    "temperature_2022_df = pd.read_csv(\"/home/wesley/github/etheleon/national_analysis/data/climate/weather_2022/Temp 2022.csv\", skiprows=1, names=snake_case_names, encoding='ISO-8859-1').loc[:, :\"dbt_min\"]\n",
    "\n",
    "expected_columns = ['rh_max', 'rh_min', 'rh_mean']\n",
    "\n",
    "# Check if each column exists in the DataFrame, and if not, add it with NaN values\n",
    "for col in expected_columns:\n",
    "    if col not in temperature_2022_df.columns:\n",
    "        temperature_2022_df[col] = np.nan\n",
    "\n",
    "temperature_2022_df.rename(columns={'station': 'station_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Combine year, month, and day into a single date column\n",
    "temperature_2022_df['date'] = pd.to_datetime(temperature_2022_df[['year', 'month', 'day']])\n",
    "temperature_2022_df.drop(columns=['year', 'month', 'day'], inplace=True)\n",
    "temperature_2022_df['date'] = temperature_2022_df['date'] # .dt.tz_localize('Asia/Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c4dc7480-9859-4ade-a832-d8012ed65477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2022-01-01\n",
       "1      2022-01-02\n",
       "2      2022-01-03\n",
       "3      2022-01-04\n",
       "4      2022-01-05\n",
       "          ...    \n",
       "2864   2022-05-27\n",
       "2865   2022-05-28\n",
       "2866   2022-05-29\n",
       "2867   2022-05-30\n",
       "2868   2022-05-31\n",
       "Name: date, Length: 2869, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_2022_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b95827da-0e6d-41ee-aa56-798c8f8e4f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/3688271409.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(lambda x: parse_date_with_filename(x, file))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      2023-04-24 00:00:00+08:00\n",
       "1      2023-04-24 00:00:00+08:00\n",
       "2      2023-04-24 00:00:00+08:00\n",
       "3      2023-04-24 00:00:00+08:00\n",
       "4      2023-04-24 00:00:00+08:00\n",
       "                  ...           \n",
       "6652   2023-08-27 00:00:00+08:00\n",
       "6653   2023-08-27 00:00:00+08:00\n",
       "6654   2023-08-27 00:00:00+08:00\n",
       "6655   2023-08-27 00:00:00+08:00\n",
       "6656   2023-08-27 00:00:00+08:00\n",
       "Name: date, Length: 6657, dtype: datetime64[ns, Asia/Singapore]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dbt_rh(os.path.join(climate_data_home, 'weather_2023'))['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bf8e7a3c-9c60-43b5-b331-34b34ae5be04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_849965/3914993196.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(lambda x: parse_date_with_filename(x, file))\n",
      "/tmp/ipykernel_849965/3914993196.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['date'] = df_filtered['date'].apply(lambda x: parse_date_with_filename(x, file))\n"
     ]
    }
   ],
   "source": [
    "temperature_df = pd.concat([\n",
    "    temperature_2009_2021_df,\n",
    "    temperature_2022_df,\n",
    "    read_dbt_rh(os.path.join(climate_data_home, 'weather_2023')),\n",
    "    read_dbt_rh(os.path.join(climate_data_home, 'weather_2024')),\n",
    "],     ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f6a9d1e9-f1f5-42c9-8267-a6ddaf3f9732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>dbt_max</th>\n",
       "      <th>dbt_min</th>\n",
       "      <th>dbt_mean</th>\n",
       "      <th>rh_mean</th>\n",
       "      <th>rh_max</th>\n",
       "      <th>rh_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-02-01</td>\n",
       "      <td>S102</td>\n",
       "      <td>28.8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>74.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>S102</td>\n",
       "      <td>30.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>72.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-02-03</td>\n",
       "      <td>S102</td>\n",
       "      <td>29.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>77.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-02-04</td>\n",
       "      <td>S102</td>\n",
       "      <td>29.6</td>\n",
       "      <td>24.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-02-05</td>\n",
       "      <td>S102</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>77.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151360</th>\n",
       "      <td>2024-04-21</td>\n",
       "      <td>S115</td>\n",
       "      <td>32.6</td>\n",
       "      <td>28.3</td>\n",
       "      <td>29.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151361</th>\n",
       "      <td>2024-04-21</td>\n",
       "      <td>S23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151362</th>\n",
       "      <td>2024-04-21</td>\n",
       "      <td>S104</td>\n",
       "      <td>35.7</td>\n",
       "      <td>25.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151363</th>\n",
       "      <td>2024-04-21</td>\n",
       "      <td>S24</td>\n",
       "      <td>33.6</td>\n",
       "      <td>26.8</td>\n",
       "      <td>29.1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151364</th>\n",
       "      <td>2024-04-21</td>\n",
       "      <td>S106</td>\n",
       "      <td>34.3</td>\n",
       "      <td>25.7</td>\n",
       "      <td>28.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151365 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date station_id  dbt_max  dbt_min  dbt_mean  rh_mean  rh_max  \\\n",
       "0      2009-02-01       S102     28.8     26.0      27.1     74.6     NaN   \n",
       "1      2009-02-02       S102     30.4     25.0      27.1     72.6     NaN   \n",
       "2      2009-02-03       S102     29.5     25.0      26.6     77.3     NaN   \n",
       "3      2009-02-04       S102     29.6     24.9      26.5     79.6     NaN   \n",
       "4      2009-02-05       S102     30.0     25.2      27.0     77.9     NaN   \n",
       "...           ...        ...      ...      ...       ...      ...     ...   \n",
       "151360 2024-04-21       S115     32.6     28.3      29.8     75.0    83.0   \n",
       "151361 2024-04-21        S23      NaN      NaN       NaN      NaN     NaN   \n",
       "151362 2024-04-21       S104     35.7     25.6      28.6     88.0    99.0   \n",
       "151363 2024-04-21        S24     33.6     26.8      29.1     79.0    91.0   \n",
       "151364 2024-04-21       S106     34.3     25.7      28.2     91.0    99.0   \n",
       "\n",
       "        rh_min  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "151360    63.0  \n",
       "151361     NaN  \n",
       "151362    51.0  \n",
       "151363    57.0  \n",
       "151364    61.0  \n",
       "\n",
       "[151365 rows x 8 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "809b2bf9-698b-460a-aaa2-a0dbd21c11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_temp_data_into_postgresql(df, connection):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Prepare the INSERT query\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO national_analysis.temperature\n",
    "    (station_id, date, dbt_max, dbt_min, dbt_mean, rh_max, rh_min, rh_mean)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over the rows in the DataFrame and insert them into the table\n",
    "    for index, row in df.iterrows():\n",
    "        cursor.execute(insert_query, (\n",
    "            row['station_id'],\n",
    "            row['date'],\n",
    "            row['dbt_max'],\n",
    "            row['dbt_min'],\n",
    "            row['dbt_mean'],\n",
    "            row['rh_max'],\n",
    "            row['rh_min'],\n",
    "            row['rh_mean']\n",
    "        ))\n",
    "\n",
    "\n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully into national_analysis.temperature!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d5ee6a7e-8836-4da3-a9c9-5af55d8bff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = temperature_df.dropna(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a8bd5d3e-bd16-483a-8be3-800a60a39b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into national_analysis.temperature!\n"
     ]
    }
   ],
   "source": [
    "insert_temp_data_into_postgresql(df_cleaned, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cebb5eff-16b3-4c37-93ca-9297a1286601",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e98c033-6f4a-4b1a-98a8-3fbe61761776",
   "metadata": {},
   "source": [
    "## Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7b609caf-5b09-462d-851c-d5ed413f66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl_file = \"/home/wesley/github/etheleon/national_analysis/tables/create_rainfall_table.sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "30b82b7a-4814-4dc3-8f80-e198d3361b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    with open(ddl_file, \"r\", encoding=\"UTF-8\") as ddl:\n",
    "        create_table_query = ddl.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "23eee4ba-5cb9-48e2-9bfa-171b59b301dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE IF NOT EXISTS national_analysis.rainfall (\\n    station_id VARCHAR(10) NOT NULL,\\n    date DATE NOT NULL,\\n    rainfall_amt_total FLOAT,\\n    rainfall_duration_min FLOAT,\\n    PRIMARY KEY (station_id, date)\\n);\\n\\nCOMMENT ON TABLE national_analysis.rainfall IS 'This table stores the total rainfall and duration of rainfall for different stations on different dates.';\\n\\nCOMMENT ON COLUMN national_analysis.rainfall.station_id IS 'Unique identifier for each weather station.';\\nCOMMENT ON COLUMN national_analysis.rainfall.date IS 'Date of the recorded rainfall event.';\\nCOMMENT ON COLUMN national_analysis.rainfall.rainfall_amt_total IS 'Total rainfall amount measured in millimeters for the day.';\\nCOMMENT ON COLUMN national_analysis.rainfall.rainfall_duration_min IS 'Total rainfall duration in minutes for the day.';\""
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0e6ded18-81ba-434d-b261-c4e9a7074f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def postgres_connection(config_file=\".secrets.toml\"):\n",
    "    conn = None\n",
    "    try:\n",
    "        cfg = load_db_config(config_file)\n",
    "        connection_string = \"postgresql+psycopg2://{}:{}@{}:5432/{}\".format(\n",
    "            cfg[\"user\"],\n",
    "            cfg[\"passwd\"],\n",
    "            cfg[\"host\"],\n",
    "            cfg[\"dbname\"],\n",
    "        )\n",
    "        engine = create_engine(connection_string)\n",
    "        yield engine\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        if conn is not None:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "93e4c4f3-de51-4523-b3e2-93a79aebcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    sql_statements = create_table_query.split(\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1730c3df-4421-4ed6-91f0-5c694eaac0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = sql_statements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c22d83b3-033f-411a-b532-9c1f457bce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS national_analysis.rainfall (\n",
    "    station_id VARCHAR(10) NOT NULL, -- Unique identifier for the weather station\n",
    "    date DATE NOT NULL, -- Date of the rainfall measurement\n",
    "    rainfall_amt_total FLOAT, -- Total rainfall amount in millimeters\n",
    "    rainfall_duration_min FLOAT, -- Duration of the rainfall in minutes\n",
    "    PRIMARY KEY (station_id, date) -- Composite primary key on station and date\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c6857d15-aa76-4f28-9ccb-53f2d1aeb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b341b153-b15c-43ce-ab6e-78651c4301f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS national_analysis.rainfall (\n",
    "    station_id VARCHAR(10) NOT NULL, -- Unique identifier for the weather station\n",
    "    date DATE NOT NULL, -- Date of the rainfall measurement\n",
    "    rainfall_amt_total FLOAT, -- Total rainfall amount in millimeters\n",
    "    rainfall_duration_min FLOAT, -- Duration of the rainfall in minutes\n",
    "    PRIMARY KEY (station_id, date) -- Composite primary key on station and date\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8c8f9ffc-3953-4f90-af43-b05d193efc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with postgres_connection(\"/home/wesley/github/etheleon/national_analysis/.secrets.toml\") as engine:\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(statement))\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3ec7cc09-dc48-408f-96aa-a3484d79ac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('public',),\n",
       " ('national_analysis',),\n",
       " ('information_schema',),\n",
       " ('pg_catalog',),\n",
       " ('pg_toast',)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedac8d6-379a-4dd2-a392-d090a2194b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    sql_statements = create_table_query.split(\";\")\n",
    "\n",
    "    # Create the table using the DDL\n",
    "    with postgres_connection(connection_params_path) as engine:\n",
    "        with engine.connect() as connection:\n",
    "            try:\n",
    "                # Execute each SQL statement individually\n",
    "                for statement in sql_statements:\n",
    "                    statement = statement.strip()  # Remove leading/trailing whitespace\n",
    "                    if statement:  # Skip empty statements\n",
    "                        print(statement)\n",
    "                        connection.execute(text(statement))\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while executing SQL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd648917-bd58-438f-869a-74cac1d5fee0",
   "metadata": {},
   "source": [
    "# Dengue cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3a4fc-4ddc-4946-9825-e3d46bb2e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_root_dir = \"/home/wesley/Dengue/\"\n",
    "shapefiles_dir = \"Shapefiles for EHI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0dbedca3-4ada-47b7-ae37-fa867d650f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster_Locallities_Active.cpg\t    Confirmed_Cluster.cpg      DF_Cases.cpg\n",
      "Cluster_Locallities_Active.dbf\t    Confirmed_Cluster.dbf      DF_Cases.dbf\n",
      "Cluster_Locallities_Active.prj\t    Confirmed_Cluster.prj      DF_Cases.prj\n",
      "Cluster_Locallities_Active.sbn\t    Confirmed_Cluster.sbn      DF_Cases.sbn\n",
      "Cluster_Locallities_Active.sbx\t    Confirmed_Cluster.sbx      DF_Cases.sbx\n",
      "Cluster_Locallities_Active.shp\t    Confirmed_Cluster.shp      DF_Cases.shp\n",
      "Cluster_Locallities_Active.shp.xml  Confirmed_Cluster.shp.xml  DF_Cases.shp.xml\n",
      "Cluster_Locallities_Active.shx\t    Confirmed_Cluster.shx      DF_Cases.shx\n"
     ]
    }
   ],
   "source": [
    "! ls /home/wesley/Dengue/Shapefiles\\ for\\ EHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f72b75a8-8569-43ae-9016-e88d16431eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/wesley/anaconda3/envs/dengue/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: packaging in /home/wesley/anaconda3/envs/dengue/lib/python3.12/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /home/wesley/anaconda3/envs/dengue/lib/python3.12/site-packages (from geopandas) (2.2.2)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Downloading pyproj-3.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Downloading shapely-2.0.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/wesley/anaconda3/envs/dengue/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/wesley/anaconda3/envs/dengue/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/wesley/anaconda3/envs/dengue/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: certifi in /home/wesley/anaconda3/envs/dengue/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /home/wesley/anaconda3/envs/dengue/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "Downloading pyogrio-0.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, pyproj, pyogrio, geopandas\n",
      "Successfully installed geopandas-1.0.1 pyogrio-0.10.0 pyproj-3.6.1 shapely-2.0.6\n"
     ]
    }
   ],
   "source": [
    "! pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2f180a90-23a1-49b2-8390-ec2e26b2d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c763af19-890d-484d-b07d-e1a8e05d4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "af9331c3-56f1-4325-8cfa-b796eccd478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/wesley/Dengue/Shapefiles for EHI/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f0102c29-1671-4f97-9d7a-098d42010b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_localities_gdf = gpd.read_file('Cluster_Locallities_Active.shp')\n",
    "confirmed_cluster_gdf = gpd.read_file('Confirmed_Cluster.shp')\n",
    "df_cases_gdf = gpd.read_file('DF_Cases.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "cbbddeb9-bf7c-45a1-9ea5-67d232907f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', None, '3', '4', '1', '1, 2', '1, 4', '3, 4', '2, 4'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cases_gdf.SEROTYPE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "119020d2-8331-4be4-a5aa-be420292aa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EWEEK</th>\n",
       "      <th>MONTH_</th>\n",
       "      <th>CASE_ID</th>\n",
       "      <th>RESIDENTIA</th>\n",
       "      <th>POSTAL</th>\n",
       "      <th>LEVEL_</th>\n",
       "      <th>NOTIFY_DAT</th>\n",
       "      <th>ONSET_DATE</th>\n",
       "      <th>DF_STATUS</th>\n",
       "      <th>PROINFAREA</th>\n",
       "      <th>SEROTYPE</th>\n",
       "      <th>CLUSTER_ID</th>\n",
       "      <th>SIZE_</th>\n",
       "      <th>YEAR_</th>\n",
       "      <th>NEA_ONSET_</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>DENF-2024-011098</td>\n",
       "      <td>2</td>\n",
       "      <td>085101</td>\n",
       "      <td>37</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>20241310</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>POINT (28850.749 28922.695)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>DENF-2024-011086</td>\n",
       "      <td>1</td>\n",
       "      <td>439866</td>\n",
       "      <td>06</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20241264</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>POINT (35290.75 31334.558)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>DENF-2024-011092</td>\n",
       "      <td>1</td>\n",
       "      <td>431008</td>\n",
       "      <td>05</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>FL13</td>\n",
       "      <td>2</td>\n",
       "      <td>20241235</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>POINT (33549.087 31664.813)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>DENF-2024-011089</td>\n",
       "      <td>1</td>\n",
       "      <td>383115</td>\n",
       "      <td>04</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>20241261</td>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-08-02</td>\n",
       "      <td>POINT (32426.683 32670.852)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>DENF-2024-011110</td>\n",
       "      <td>1</td>\n",
       "      <td>381003</td>\n",
       "      <td>11</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>POINT (32347.248 32901.991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11585</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>DENF-2024-011914</td>\n",
       "      <td>1</td>\n",
       "      <td>680103</td>\n",
       "      <td>07</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>FL826</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>POINT (19123.415 39901.789)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11586</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>DENF-2024-011925</td>\n",
       "      <td>2</td>\n",
       "      <td>788545</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>POINT (27612.556 40319.174)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11587</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>DENF-2024-011912</td>\n",
       "      <td>1</td>\n",
       "      <td>730339</td>\n",
       "      <td>03</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>POINT (22244.757 45858.775)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11588</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>DENF-2024-011909</td>\n",
       "      <td>1</td>\n",
       "      <td>730514</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-09-04</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>POINT (23142.86 46256.101)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11589</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>DENF-2024-011920</td>\n",
       "      <td>1</td>\n",
       "      <td>730869</td>\n",
       "      <td>04</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>FL246</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>POINT (23623.684 47140.309)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11590 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EWEEK MONTH_           CASE_ID RESIDENTIA  POSTAL LEVEL_ NOTIFY_DAT  \\\n",
       "0        32      8  DENF-2024-011098          2  085101     37 2024-08-06   \n",
       "1        32      8  DENF-2024-011086          1  439866     06 2024-08-06   \n",
       "2        32      8  DENF-2024-011092          1  431008     05 2024-08-06   \n",
       "3        32      8  DENF-2024-011089          1  383115     04 2024-08-06   \n",
       "4        32      8  DENF-2024-011110          1  381003     11 2024-08-06   \n",
       "...     ...    ...               ...        ...     ...    ...        ...   \n",
       "11585    36      9  DENF-2024-011914          1  680103     07 2024-09-03   \n",
       "11586    36      9  DENF-2024-011925          2  788545   None 2024-09-03   \n",
       "11587    36      9  DENF-2024-011912          1  730339     03 2024-09-03   \n",
       "11588    36      9  DENF-2024-011909          1  730514     12 2024-09-04   \n",
       "11589    36      9  DENF-2024-011920          1  730869     04 2024-09-03   \n",
       "\n",
       "      ONSET_DATE   DF_STATUS PROINFAREA SEROTYPE CLUSTER_ID  SIZE_ YEAR_  \\\n",
       "0     2024-08-06  Indigenous       None        2   20241310      2  2024   \n",
       "1     2024-08-06  Indigenous       None     None   20241264      2  2024   \n",
       "2     2024-08-04  Indigenous       FL13        2   20241235      4  2024   \n",
       "3     2024-08-01  Indigenous       None        3   20241261      5  2024   \n",
       "4     2024-07-30  Indigenous       None     None          0      0  2024   \n",
       "...          ...         ...        ...      ...        ...    ...   ...   \n",
       "11585 2024-09-03  Indigenous      FL826     None          0      0  2024   \n",
       "11586 2024-08-31  Indigenous       None     None          0      0  2024   \n",
       "11587 2024-09-03  Indigenous       None     None          0      0  2024   \n",
       "11588 2024-09-03  Indigenous       None     None          0      0  2024   \n",
       "11589 2024-09-03  Indigenous      FL246     None          0      0  2024   \n",
       "\n",
       "      NEA_ONSET_                     geometry  \n",
       "0     2024-08-06  POINT (28850.749 28922.695)  \n",
       "1     2024-08-06   POINT (35290.75 31334.558)  \n",
       "2     2024-08-04  POINT (33549.087 31664.813)  \n",
       "3     2024-08-02  POINT (32426.683 32670.852)  \n",
       "4     2024-07-30  POINT (32347.248 32901.991)  \n",
       "...          ...                          ...  \n",
       "11585 2024-09-03  POINT (19123.415 39901.789)  \n",
       "11586 2024-08-31  POINT (27612.556 40319.174)  \n",
       "11587 2024-09-03  POINT (22244.757 45858.775)  \n",
       "11588 2024-09-03   POINT (23142.86 46256.101)  \n",
       "11589 2024-09-03  POINT (23623.684 47140.309)  \n",
       "\n",
       "[11590 rows x 16 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cases_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4a0ea277-3c04-415a-abc6-487ac0ac5700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cases_gdf.SIZE_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f26eb397-c619-4e66-8718-7b7e68e38844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cases_gdf.query(\"SIZE_ == 412\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d13f18-1124-4331-9866-5e49488c1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "coi = [\"CASE_ID\", \"CLUSTER_ID\", \"NEA_ONSET_\", \"SEROTYPE\", \"RESIDENTIA\", \"POSTAL\"]\n",
    "\n",
    "column_mapping = {\n",
    "    \"CASE_ID\": \"case_id\",         # Rename CASE_ID to case_id\n",
    "    \"CLUSTER_ID\": \"cluster_id\",   # Rename CLUSTER_ID to cluster_id\n",
    "    \"NEA_ONSET_\": \"date\",         # Rename NEA_ONSET_ to date\n",
    "    \"SEROTYPE\": \"serotype\",       # Rename SEROTYPE to serotype\n",
    "    \"RESIDENTIA\": \"residential\",  # Rename RESIDENTIA to residential\n",
    "    \"POSTAL\": \"postal\"            # Rename POSTAL to postal\n",
    "}\n",
    "\n",
    "\n",
    "df_cases = df_cases_gdf.loc[:, coi].rename(columns=column_mapping)\n",
    "\n",
    "\n",
    "df_cases['cluster_id'] = df_cases['cluster_id'].replace('0', np.nan)\n",
    "\n",
    "# df_cases.query(\"case_id == 'DENF-2024-011914'\")\n",
    "\n",
    "df_cases['serotype'] = df_cases['serotype'].apply(\n",
    "    lambda x: [int(s.strip()) for s in x.split(',')] if isinstance(x, str) else []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6d11a6e0-7d68-40bd-8ced-f8fe6dc16f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from psycopg2 import sql\n",
    "\n",
    "def insert_data_into_postgresql(df, connection):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    insert_query = sql.SQL(\"\"\"\n",
    "        INSERT INTO national_analysis.dengue_fever_cases (\n",
    "            case_id, postal, cluster_id, residential, date, serotype\n",
    "        ) VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\")\n",
    "\n",
    "    # Iterate over the rows in the DataFrame and insert them into the table\n",
    "    for index, row in df.iterrows():\n",
    "        cursor.execute(insert_query, (\n",
    "            row['case_id'],                                   # Case ID (as a string or formatted value)\n",
    "            row['postal'],                                    # Postal code as string (or integer if needed)\n",
    "            int(row['cluster_id']) if pd.notnull(row['cluster_id']) else None,  # Handle cluster_id and convert to int\n",
    "            row['residential'],                               # Residential field as string\n",
    "            row['date'] if pd.notnull(row['date']) else None, # Handle NA dates\n",
    "            row['serotype']                                   # Serotype should be passed as a list of integers or strings\n",
    "        ))\n",
    "\n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully into national_analysis.df_cases!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "dcfd7d8d-fa69-4bf6-9f1c-5173c8273277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into national_analysis.df_cases!\n"
     ]
    }
   ],
   "source": [
    "insert_data_into_postgresql(df_cases, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "51a8a229-7f92-4dfb-b9f5-00a2f8528dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9feba45-a536-45ee-ae4c-04e3521c8a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
